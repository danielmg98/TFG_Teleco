 hola 00:01
 vale muchas gracias a bueno muchas gracias a todos por la presentación 00:08
 y bueno ya como se ha dicho os voy a hacer la presentación de la tesis de máster con la que he ganado este premio 00:13
 y quería empezar esta presentación mostrando mis agradecimientos en primer lugar al Consorcio Mavir por la creación de este premio y a las empresas patrocinadoras que que podemos ver aquí 00:27
 mi mayor también quiero mostrar mi agradecimiento al jurado que ha tenido que tomar la decisión 00:33
 mi mayor agradecimiento ahora va dedicado a mi director Anselmo Peñas al cual le tengo que dedicar mucho lo que ha sido mi carrera investigadora 00:41
 también dar las gracias a todos mis compañeros y amigos que me han estado apoyando y todavía siguen en ello a pesar de de que siempre estoy comiéndome la cabeza con mis investigaciones 00:53
 y en último lugar aunque no por ello menos importante quiero agradecer y dedicar este premio a toda mi familia 00:59
 bueno vamos ahora a ver la presentación 01:02
 este es el esquema que voy a seguir durante la presentación 01:05
 comenzaré realizando una introducción donde definiré unos términos que nos van a ser de utilidad para el resto de la presentación 01:13
 entre ellos está la tarea variación de respuestas ya que en el siguiente punto realizaré una propuesta de evaluación de sistemas de este tipo 01:21
 a continuación realizaré una propondré una aproximación basada en reconocimiento de entidades para la validación de respuestas 01:30
 y terminaré dando algunas conclusiones del trabajo y las publicaciones a las que dio lugar 01:35
 empezamos por la introducción 01:37
 los sistemas de búsqueda de respuestas son sistemas que reciben una pregunta en lenguaje natural y generan una respuesta a dicha pregunta y un texto que soporta la veracidad de dicha respuesta 01:50
 al contrario de los sistemas de recuperación como los motores de búsqueda como Google o Yahoo a los cuales se les consulta con preguntas con perdón palabras clave y genera una lista de documentos donde manualmente tenemos que buscar nosotros las respuestas 02:04
 con lo cual facilitan el acceso a la información 02:06
 un ejemplo puede ser el que muestro aquí 02:09
 para la pregunta cuál es la longitud de río Tajo 02:12
 podemos obtener de un sistema la respuesta 02:15
 mil siete kilómetros y como texto para soportar la dicha respuesta el Tajo es el río más largo de la Península Ibérica con un total de mil siete kilómetros que el cual nos demuestra que la respuesta obtenida es correcta 02:28
 por otro lado tenemos la tarea de validación de respuestas que consiste en decidir si las respuestas generadas por los sistemas de búsqueda de respuestas son o no correctas 02:38
 para ello un sistema de validación recibiría al igual que el sistema de búsqueda de respuestas la pregunta y la la respuesta y texto soporte generado por los sistemas de búsqueda de respuestas generando como salida un valor binario indicando si considera que la respuesta es o no correcta de acuerdo al texto soporte 02:57
 en el ejemplo anterior que tenemos un sistema de validación debería indicar que la respuesta es correcta según el texto 03:04
 de este modo al incluir al poder incluir criterios para considerar los sistemas de búsqueda de respuestas para considerar si sus respuestas son o no correctas se espera que se mejoren los resultados obtenidos actualmente sin validación de respuestas 03:19
 y ahora voy a hablar de reconocimiento de implicación textual 03:24
 es una tarea que consiste en determinar dado un texto si su significado implica al de otro texto al que llamamos hipótesis o lo que podemos decir de otra manera si el significado del texto llamado hipótesis está se puede obtener a partir del primer texto 03:39
 un ejemplo muy sencillo lo podemos ver aquí 03:42
 dado el texto Luis y Ana se casaron el treinta de enero en Madrid 03:46
 y la hipótesis Luis es el marido de Ana 03:49
 si no tenemos ninguna noticia de que haya habido un divorcio podemos ver que hay implicación entre el texto hipótesis 03:55
 usando esta idea de implicación textual nosotros realizamos una propuesta de evaluación de sistemas de validación de respuestas que voy a exponer ahora mismo la metodología propuesta 04:06
 para ello propusimos las el uso de la siguiente arquitectura 04:11
 tenemos la arquitectura básica un sistema de pregunta de búsqueda de respuestas que recibe una pregunta y como ya hemos dicho genera una respuesta candidata y un texto soporte 04:22
 y por otro lado un sistema de validación que recibiría la misma pregunta y la respuesta y el texto soporte de por el sistema de búsqueda de respuestas 04:32
 de tal manera que el sistema de validación genera indica si la respuesta es o no correcta 04:38
 en caso de que no sea correcta podemos volver a preguntar por una podemos volver a realizar otra consulta con el fin de encontrar en este caso una respuesta correcta 04:47
 al usar implicación textual como he dicho que tenemos texto y e hipótesis vemos que nos falta la hipótesis con lo cual tiene que haber un paso intermedio de generación de hipótesis 04:59
 ese es el caso es lo que debemos de incluir al usar implicación textual en la validación de respuestas 05:05
 es por ello que los pasos a seguir para usar implicación textual para la validación de respuestas el primero sería generar diversas hipótesis combinando preguntas y respuestas 05:19
 de tal modo que si tenemos la pregunta quién es Vicente Fox 05:22
 y la respuesta y una respuesta generada que es presidente de Méjico 05:26
 una posible hipótesis es Vicente Fox es el presidente de Méjico 05:30
 teniendo ya esa hipótesis y el texto soporte podemos usar implicación textual para comprobar si hay si el texto soporte implica la hipótesis creada y por tanto si la respuesta es o no válida 05:43
 una vez tenemos una esa arquitectura es necesario crear unas colecciones de evaluación para poder usar los sistemas de validación que utilizan implicación textual 05:56
 por tanto nosotros también desarrollamos un método en el que tomábamos como partida la salida la salida de sistemas reales de búsqueda de respuestas y los juicios otorgados por evaluadores humanos a dichas respuestas 06:10
 el el objetivo es construir un conjunto de pares texto hipótesis sobre los cuales se va a evaluar 06:18
 primer paso es crear las hipótesis 06:20
 para ello necesitamos a a partir de la pregunta crear un patrón de hipótesis como por un patrón de hipótesis en el que luego se instancian las distintas respuestas 06:32
 lo podemos ver mejor aquí en el ejemplo 06:35
 si tenemos la pregunta cuál es la capital de Croacia 06:38
 podemos crear como posible patrón de hipótesis una posible respuesta es la capital de Croacia 06:44
 y ya con cada respuesta generada por los sistemas de búsqueda podemos ir creando diversas hipótesis instanciando este patrón 06:52
 de tal manera que si una respuesta es Zagreb podemos tener la hipótesis 06:56
 Zagreb es la capital de Croacia 06:58
 de este modo con esta hipótesis y el texto soporte devuelto ya tenemos un par texto hipótesis para esta respuesta generada 07:06
 el siguiente paso es qué valor de implicación otorgar a este par 07:12
 dado que en los sistemas de búsqueda de respuestas los evaluadores pueden otorgar cuatro posibles valores y en implicación textual solamente hay dos posibles valores es necesario hacer una transformación 07:23
 es por ello que nosotros proponemos esta transformación 07:27
 caso de respuesta correcta la consideran los evaluadores cuando la respuesta a la pregunta es correcta y soportada por el texto 07:35
 por lo tanto cabe esperar que el texto implique a la hipótesis que generamos con el método propuesto y por tanto será un valor positivo de implicación 07:44
 caso de respuestas no soportadas se lo otorgan los evaluadores cuando aun siendo la respuesta cierta no se puede soportar su veracidad con el texto soporte 07:55
 en este caso la reformulación de la hipótesis no va a ser implicada por el texto 08:00
 por tanto no habrá implicación y lo indicamos 08:03
 caso de respuestas incorrectas es también es es semejante 08:09
 no el texto no va a implicar la hipótesis generada puesto que la respuesta es incorrecta y no va a haber implicación 08:16
 caso de las respuestas sean exactas es un caso más difícil 08:19
 este tipo de de de juicio se otorga cuando la respuesta es en parte correcta pero puede ser más larga o más corta de lo estrictamente necesario 08:31
 las hipótesis que se generan no está claro si son ciertas o no 08:35
 teniendo en cuenta que son una un bajo porcentaje de todas las respuestas otorgadas por sistemas decidimos eliminarlas para nuestros fines de evaluación 08:45
 una vez tenemos las colecciones de evaluación el siguiente paso es describir la las medidas con la cual se va a evaluar y sobre todo comparar los distintos sistemas 08:58
 decidimos descartar el uso de una medida global dado que en los sistemas actuales cuando presentamos este trabajo de buscar respuestas un alto porcentaje de respuestas eran evaluadas como incorrectas bueno un setenta por ciento observamos en la tarea de buscar respuestas del del CLEF 09:17
 y se tenía la posibilidad de que un sistema de validación que siempre diera siempre devolviera que no en esta situación tendría un valor de de medida un valor de evaluación del setenta por ciento de precisión lo cual parece muy alto para un sistema tan sencillo y para nuestros fines de evaluación 09:35
 es por ello que nuestro interés se centra en concentrarse en la detección de respuestas correctas 09:41
 nosotros proponemos medir la precisión cobertura y su media armónica más conocida como medida efe sobre las respuestas correctas 09:49
 aquí podemos ver las fórmulas 09:52
 en el caso de la precisión nuestro objetivo es medir la habilidad de los sistemas prediciendo respuestas correctas 10:01
 caso de la cobertura se encarga de de observar y medir la capacidad de los sistemas detectando las respuestas correctas que existen 10:09
 y la medida efe lo que hace es ponderar ambos valores dándoles la misma importancia 10:14
 una vez desarrollamos esta metodología la pusimos en marcha como una tarea de evaluación llamada Answer Validation Exercise dentro del Cross Language Evaluation Forum del que ha hablado Paul 10:28
 y que la realizamos en el dos mil seis 10:30
 también se ha ido se ha ido realizando los siguientes años 10:33
 y nuestro objetivo era evaluar los los distintos enfoques que que había para validación de respuestas 10:40
 para ello tomamos como entrada la salida de los sistemas de búsqueda de respuestas que participaban en el CLEF que eran sistemas reales 10:48
 y lo pudimos desarrollar de dado la multilingualidad del CLEF en siete lenguas distintas 10:55
 tuvimos una gran aceptación y una gran participación con once grupos participantes y un total de treinta y ocho ejecuciones en distintos idiomas 11:03
 ahora voy a hablaros de la aproximación que nosotros proponemos para validación de respuestas basándonos en reconocimiento de entidades 11:12
 para ello primero voy a pasar a definiros lo que nosotros consideramos entidades 11:17
 nosotros llamamos entidades a lo que son los nombres de personas organizaciones o localizaciones como nombres de países o ciudad también las expresiones numéricas y las expresiones temporales 11:29
 nuestra motivación para trabajar con entidades en reconocimiento de implicación textual y validación fue que observando las colecciones de búsqueda de respuestas las preguntas que había en las colecciones un alto porcentaje esperaban como respuesta una entidad no 11:46
 pues ser un lugar un nombre de una persona una organización 11:51
 son las consultas más frecuentes que hay 11:53
 además en implicación textual en el foro más importante que se celebra el RTE Challenge observamos que en las colecciones que se proponían para test también había un alto porcentaje de entidades 12:05
 con lo cual queríamos estudiar su importancia en esta tarea 12:09
 dado que en en implicación textual se considera que para que haya implicación todos los elementos de la hipótesis han de ser implicados por elementos del texto llevando esto al campo de las entidades nuestra propuesta es que todas las entidades de la hipótesis deben de estar implicadas por entidades en el en el texto 12:29
 de este modo nosotros realizamos dos propuestas sobre sobre implicación de entidades 12:36
 en nuestra primera aproximación decidimos no usar la clasificación de entidades que he hablado de nombres expresiones numéricas expresiones temporales 12:44
 de este modo consideramos que una entidad implica a otra si el si el texto de la primera perdón si el texto de la primera contiene al texto de la segunda 12:53
 en el ejemplo la entidad dos de agosto de mil novecientos noventa implicaría mil novecientos noventa 12:59
 lo cual podemos ver que en este caso es correcto 13:01
 nuestra segunda aproximación la cual es más elaborada tiene en cuenta la clasificación de entidades dadas por los reconocedores actuales de entidades 13:11
 diferenciamos entre nombres expresiones temporales y numéricas y hay que definir un tipo de de implicación en dependiendo del tipo de entidad que tenemos 13:20
 caso de nombres semejante a la anterior 13:23
 una entidad implica a otra 13:25
 si la primera implica si la primera contiene a la segunda 13:28
 en el ejemplo Yasir Arafat implica Arafat 13:31
 lo cual podemos ver que es claro 13:33
 caso de expresiones temporales consideramos que una expresión temporal implica a otra si el rango de la primera está incluido en la segunda 13:40
 un ejemplo muy sencillo es que el dos de agosto implica a agosto 13:45
 podemos ver que algo que ha ocurrido en esa fecha el dos de agosto también ha ocurrido en agosto o es un periodo de tiempo mayor 13:52
 caso de expresiones numéricas una expresión numérica implica a otra si el rango asociado a la segunda incluye al rango de la primera 14:01
 de manera similar a expresiones temporales 14:03
 podemos ver en el ejemplo que cinco mil implica más de dos mil 14:06
 lo cual también está claro 14:08
 con el fin de comparar estas dos estas dos aproximaciones realizamos un experimento sobre una colección de implicación textual balanceada con igual porcentaje de ejemplos de implicación y ejemplos de no implicación usando como medida de evaluación la accuracy que se suele usar en esta tarea que es el porcentaje de pares acertados 14:29
 y nuestra hipótesis de partida era que el método más elaborado que tenía en cuenta clasificación iba a obtener mejores resultados 14:36
 sin embargo viendo los resultados vimos que son muy semejantes dado que nos enfrentamos y arrastramos el error en la clasificación de los actuales reconocedores 14:47
 se puede ver el error en este ejemplo donde la expresión mil novecientos noventa que en este caso es un año una expresión temporal se reconoce como un número 14:56
 en esta expresión numérica no encontraría otra expresión numérica en el texto que la implicase y ahí tendríamos un error y un problema 15:04
 por ello decidimos usar el método menos elaborado que no tiene clasificación dado que es más robusto a a errores en la clasificación y además es más sencillo 15:15
 usando este método realizamos una serie de experimentos en el AVE 2006 también la realizamos con otros sistemas para ver para realizar un estudio 15:27
 el primero de los sistemas era un clasificador SVM que utilizaba varias características de solapamiento léxico porcentaje de palabras de la hipótesis en el texto porcentaje de lemas bigramas y trigramas de la hipótesis en el texto 15:43
 por bigramas me refiero dos lemas consecutivos trigramas tres lemas consecutivos 15:47
 son son atributos de solapamiento muy sencillos 15:51
 el segundo sistema que que quisimos poner a prueba es usaba la implicación de entidades que he descrito considerando que había implicación si todas las entidades que había en la hipótesis que había sido generada a partir de pregunta a partir de pregunta y respuesta como he explicado antes estaban implicadas y no en caso contrario 16:12
 y también decidimos comprobar los resultados de una serie de combinaciones de estos sistemas 16:17
 podemos ver que nuestro sistema SVM a pesar de usar perdón 16:24
 perdón nuestro sistema SVM a pesar de usar atributos muy sencillos solapamiento léxico obtenía un valor por encima del baseline otorgado por otorgado en la por la organización 16:49
 y se quedaba más o menos cerca del de ese mejor sistema en el AVE 2006 16:54
 también quisimos poner a prueba nuestro sistema de entidades el cual mejoraba todavía más mejoraba los todavía más al sistema baseline y al sistema SUV que nosotros hemos realizado y nos quedábamos también todavía más cerca del mejor sistema del AVE 2006 que era un sistema que utilizaba procesamientos más complejos 17:16
 decidimos que dada la alta precisión de nuestro sistema de de entidades reconociendo pares negativos pares donde no hay implicación las respuestas son incorrectas una buena idea era probar a usarlo como filtro para el sistema SVM 17:30
 de tal manera que nos quitásemos todos los pares sin implicación con una alta precisión y luego el sistema SVM decidiera en cuáles había implicación y en cuáles no 17:40
 nuestra intuición no funcionó ya que obtuvimos resultados más bajos que los sistemas que combinaba 17:49
 y otra combinación que realizamos era la de incluir las entidades como un atributo más en la en el aprendizaje en el SVM 17:57
 en este caso podemos ver que los resultados son mejores que los presentados y muy cercanos apenas similares a los del mejor sistema 18:06
 esto nos hace ver y nos nos hace ver que la información de entidades es muy importante en este campo y de hecho los mejores sistemas que hay actualmente tanto en validación como en implicación tienen la la el reconocimiento de entidades como uno como uno de los atributos más importantes de sus sistemas 18:25
 también decidimos probar en en un foro de en el foro de evaluación de implicación textual que se celebró el año pasado ya que en este foro se generan pares para evaluar de que capturan características de distintas tareas del lenguaje natural no solamente búsqueda de respuestas sino también extracción de información recuperación de información y resumen automático 18:50
 en en las ejecuciones que que realizamos vimos que en la en la perdón la tarea que más entidades nombradas tenía era la extracción de información 19:00
 la información que nos otorgaban sus sistemas de entidades no nos hacía mejorar mucho ya que era necesaria todavía más información 19:08
 sin embargo seguíamos manteniendo buenos resultados en búsqueda de respuestas 19:12
 de hecho era donde mejor resultados obteníamos 19:15
 y ahora algunas conclusiones a las que llegamos con ese trabajo son que es posible reformular la validación de respuestas como un problema de reconocimiento de implicación textual 19:28
 por ello realizamos una propuesta metodológica que llevamos a cabo con éxito como una tarea de evaluación internacional en la cual hubo varios participantes y se ha seguido realizando esa tarea 19:40
 también estudiamos una aproximación para validación de respuestas en la implicación textual basándonos en entidades en las cuales obtuvimos resultados prometedores 19:49
 pero pero vimos que había ahí un margen de mejora usando esa información que se puede complementar para obtener mejores resultados 19:57
 estas son las publicaciones a las cuales dio lugar este trabajo 20:02
 y su continuación luego ha dado lugar todavía a más publicaciones 20:06
 y ya este es el fin de la presentación 20:08
 si tenéis alguna duda 20:09
 bueno muchas gracias por atender primero 20:11
 si tenéis alguna duda estaré encantado de resolvérosla 20:14
