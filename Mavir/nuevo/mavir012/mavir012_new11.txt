entonces
bueno
entonces
la
charla
la
voy
a
dar
en
español
con
subtítulos
en
inglés
.
y
bueno
la
idea
de
esta
charla
es
hablarle
yo
o
sea
uno
siempre
cuando
tiene
que
proponer
una
charla
uno
no
sabe
a
quién
le
va
a
estar
hablando
entonces
yo
pensé
y
espero
que
mi
hipótesis
sea
la
correcta
que
es
para
hablar
a
la
gente
que
sabe
algo
de
búsqueda
de
información
basada
en
texto
.
y
la
idea
es
no
mostrarlo
en
lo
que
se
bueno
sí
lo
que
se
hace
lo
que
se
está
haciendo
ahora
un
poco
más
allá
del
texto
como
que
para
que
los
que
hacen
que
trabajan
con
texto
darle
algunas
ideas
de
ir
más
allá
no
.
para
poder
ir
hacia
hacia
el
tema
del
multimedia
este
este
trabajo
bueno
o
sea
es
bajo
mi
nombre
pero
en
realidad
hay
mucha
gente
que
ha
trabajado
para
mí
en
general
son
los
estudiantes
que
hacen
el
trabajo
entonces
bueno
nos
los
voy
a
citar
porque
si
no
no
entra
no
en
la
en
la
primera
página
.
pero
bueno
entonces
lo
que
quería
decir
es
que
bueno
los
que
han
estado
en
la
clase
que
he
presentado
aquí
donde
durante
los
últimos
dos
días
que
a
pesar
del
hecho
de
que
multimedia
tiene
la
palabra
multi
eso
no
quiere
decir
que
vamos
a
ver
muchas
medias
puede
pasar
pero
en
general
se
trata
una
de
las
medias
que
no
es
texto
y
eso
se
de
así
hablamos
del
multimedia
.
como
la
charla
no
es
muy
muy
larga
lo
que
voy
a
hacer
es
que
les
voy
a
presentar
todo
sobre
imagen
entonces
deberíamos
cambiar
el
título
para
Beyond
textbesed
image
retrieval
aunque
muchas
de
estas
ideas
se
pueden
pasar
al
sonido
como
lo
pude
mostrar
los
últimos
días
a
a
los
alumnos
de
la
de
la
UNED
y
de
la
Carlos
Tercero
.
y
creo
que
también
de
la
politécnica
ok
entonces
bueno
por
qué
Textbased
qué
es
esto
de
Textbased
multimedia
retrieval
.
bueno
lo
típico
es
un
motor
por
ejemplo
Google
Images
Search
donde
uno
pone
una
palabra
y
de
manera
mágica
aparecen
imágenes
que
son
excelentes
.
por
ejemplo
uno
pone
una
query
por
ejemplo
mi
nombre
y
aparecen
cuadros
de
mi
papá
o
aparecen
el
la
portada
de
un
libro
que
hizo
mi
mamá
.
y
entonces
cómo
hace
el
sistema
para
ser
tan
inteligente
para
conseguir
este
tipo
de
imágenes
no
.
entonces
esa
es
una
de
las
primeras
preguntas
que
que
las
vamos
a
ver
enseguida
pero
esto
es
el
hecho
de
que
funcione
tan
bien
ha
hecho
que
simplemente
toda
la
gente
que
hace
productos
comerciales
usa
el
texto
.
el
texto
es
de
verdad
un
método
genial
para
conseguir
información
multimedia
.
en
qué
se
basa
este
este
método
bueno
es
muy
simple
o
sea
va
a
buscar
dentro
de
la
página
va
a
buscar
por
ejemplo
si
hay
un
link
y
a
ver
si
pasa
algo
por
ejemplo
sale
algo
sobre
mi
nombre
consigue
la
página
y
basado
en
esto
va
a
decir
ah
bueno
aquí
hay
algo
interesante
y
y
va
a
agarrar
por
ejemplo
el
nombre
de
de
la
imagen
que
va
a
ser
por
ejemplo
y
a
a
partir
de
eso
va
a
decir
ok
genial
.
eso
debe
ser
de
ese
debe
ser
de
.
ahora
si
ahora
he
puesto
un
nombre
de
otra
persona
hubiese
puesto
por
ejemplo
Nurenberger
punto
entonces
hubiese
aparecido
Nurenberger
.
ok
bueno
eso
es
básicamente
y
me
imagino
que
ustedes
todos
lo
tienen
claro
es
el
truco
de
conseguir
la
información
basado
en
texto
.
entonces
ah
bueno
esto
era
para
dar
el
ejemplo
de
de
buscar
la
palabra
.
entonces
qué
es
lo
que
vamos
a
ver
en
esta
presentación
.
bueno
lo
primero
que
vamos
a
ver
es
que
puede
pasar
aunque
ustedes
no
lo
crean
que
puede
pasar
es
que
no
hay
información
textos
.
o
que
tenemos
una
imagen
y
simplemente
no
está
muy
bien
anotada
eso
fue
todo
lo
que
les
presentó
esta
mañana
Paul
y
bueno
entonces
la
idea
sería
bueno
cómo
hacer
para
crear
ese
texto
porque
si
el
texto
funciona
también
bueno
genial
.
vamos
a
hacerlo
por
esa
misma
razón
toda
la
la
Unión
Europea
financia
muy
bien
este
tipo
de
proyectos
porque
le
parece
ah
como
el
texto
funciona
bien
vamos
a
hacer
algo
que
nos
permita
automáticamente
a
partir
de
una
imagen
hacer
un
texto
.
esa
es
la
idea
que
hay
en
el
CLEF
el
CLEF
la
idea
es
decir
ah
bueno
como
hay
sistemas
de
traducción
de
texto
a
texto
no
podríamos
hacer
un
sistema
de
traducción
por
ejemplo
de
imagen
a
texto
.
que
no
era
la
idea
inicial
pero
es
la
idea
que
se
está
haciendo
ahora
mucho
en
CLEF
.
entonces
a
ese
tema
cuando
veamos
ese
tema
de
repente
va
a
ser
con
la
guau
.
qué
pasó
yo
no
veo
ahí
ven
el
ven
el
mouse
o
no
.
ok
entonces
lo
que
vamos
a
ver
es
una
técnica
un
poco
particular
que
crea
algo
que
se
llaman
diccionarios
visuales
.
y
vamos
a
ver
que
esto
es
bastante
parecido
al
texto
y
se
y
yo
pienso
que
las
técnicas
de
texto
más
avanzadas
pueden
ayudar
aquí
a
obtener
algo
más
interesante
.
les
voy
a
demostrar
eso
pero
como
estos
métodos
no
son
perfectos
vamos
a
ver
otro
axis
que
sería
un
axis
intermedio
de
cómo
combinar
textos
y
imágenes
no
.
entonces
aquí
la
idea
va
a
ser
por
ejemplo
cómo
mejorar
un
Textbased
retrieval
clásico
como
el
que
acabamos
de
ver
el
de
Google
Search
y
cómo
hacer
para
mejorarlo
usando
conceptos
visuales
.
ok
y
la
tercera
parte
es
algo
completamente
diferente
que
les
puede
parecer
raro
es
vamos
a
ver
si
podemos
conseguir
texto
pero
esta
vez
utilizando
imágenes
.
parece
raro
parece
difícil
bueno
los
que
se
queden
hasta
el
final
lo
verán
.
ok
entonces
por
qué
es
por
qué
puede
ser
este
interesante
de
tratar
de
no
solamente
focalizarse
en
el
texto
pero
si
no
focalizar
un
poco
en
el
media
es
que
de
repente
puede
ser
que
no
hay
no
hay
texto
simplemente
alrededor
.
ahora
lo
que
puede
también
pasar
es
que
el
media
que
está
alrededor
no
describe
la
imagen
.
por
ejemplo
podemos
tener
una
foto
de
un
personaje
vestido
de
azul
o
de
verde
o
de
lo
que
sea
y
la
descripción
o
un
producto
comercial
y
la
descripción
no
tiene
la
información
escrita
de
manera
escrita
en
el
texto
de
qué
es
el
los
colores
que
aparecen
en
esa
imagen
.
entonces
en
ese
caso
no
vamos
a
poder
conseguir
esa
imagen
basado
en
el
texto
porque
simplemente
en
el
texto
esa
información
no
aparece
.
ok
entonces
bueno
la
idea
es
ok
muy
bien
vamos
a
agarrar
y
vamos
a
hacer
un
traductor
automático
que
nos
va
a
transformar
el
media
en
el
texto
.
es
un
poco
también
lo
que
se
hace
que
se
está
empezando
a
hacer
ahora
con
el
audio
.
en
el
audio
lo
que
se
hace
es
bueno
vamos
a
tratar
de
hacer
un
sistema
un
motor
por
ejemplo
el
proyecto
europeo
Cuero
bueno
vamos
a
buscar
información
dentro
del
video
bueno
la
idea
es
decir
bueno
que
de
dónde
podemos
sacar
texto
.
ah
trascripción
automática
entonces
conseguimos
el
texto
y
así
vamos
a
poder
conseguir
información
dentro
del
audio
dentro
del
del
media
basándose
en
el
texto
.
ok
bueno
entonces
si
necesitan
un
traductor
hay
hay
hay
básicamente
dos
maneras
.
una
es
decir
ok
hacemos
eso
de
manera
manual
lo
que
pasa
es
que
uno
cuesta
mucho
.
segundo
es
muy
muy
lento
y
con
la
cantidad
de
información
que
tenemos
y
que
aparece
cada
día
va
a
ser
bastante
difícil
.
y
además
si
pasamos
a
grandes
escalas
vamos
a
tener
un
problema
de
lo
que
hablaban
esta
mañana
la
la
gente
que
trabaja
en
documentación
que
es
bastante
difícil
para
poder
tener
un
vocabulario
unificado
y
que
sea
igual
para
todas
las
personas
que
anotan
.
ese
se
puede
complicar
muy
rápidamente
pero
claro
la
calidad
de
la
anotación
puede
ser
bastante
de
alta
calidad
.
entonces
la
idea
es
inventar
un
sistema
donde
uno
puede
mostrar
una
imagen
y
esa
imagen
les
va
a
decir
a
ustedes
ah
ok
.
lo
que
yo
veo
ahí
es
no
sé
cielo
por
ejemplo
o
veo
un
poco
de
de
hierbas
o
veo
un
bosque
o
veo
un
lago
.
que
hay
simple
eso
son
lo
que
más
o
menos
clasificadores
bastante
simples
.
entonces
cómo
cómo
se
puede
hacer
un
clasificador
de
ese
tipo
.
hay
básicamente
dos
ideas
una
es
inventar
como
una
receta
de
cocina
que
dice
por
ejemplo
si
hacemos
tal
cosa
tal
cosa
entonces
detectamos
que
hay
por
ejemplo
una
cara
.
una
técnica
muy
especializada
para
un
un
concepto
muy
especializado
.
este
para
presentarles
eso
debería
presentarle
a
ustedes
concepto
por
concepto
del
diccionario
y
explicarles
la
técnica
específica
no
.
entonces
lo
que
nosotros
proponemos
o
que
más
bien
la
comunidad
científica
propone
es
utilizar
algo
como
machine
learning
aprendizaje
artificial
y
la
idea
es
de
aprender
a
partir
de
ejemplos
.
o
sea
le
vamos
a
mostrar
a
la
máquina
ejemplos
la
la
la
la
computadora
o
el
algoritmo
va
a
tratar
de
generalizar
algo
conseguir
alguna
repetición
dentro
de
la
información
algo
en
lo
que
se
va
a
repetir
y
nos
va
a
extraer
esa
información
y
cuando
mostramos
algo
nuevo
va
a
decir
ok
.
vamos
a
aprender
cómo
para
darles
un
ejemplo
vamos
a
tener
ejemplos
positivos
y
negativos
que
pueden
ser
que
sea
o
carros
de
un
lado
y
cualquier
cosa
del
otro
o
vacas
de
un
lado
y
y
cualquier
cosa
.
se
lo
mostramos
al
sistema
de
clasificación
y
él
va
a
aprender
no
sé
cualquier
cosa
alguna
regularidad
algo
que
se
repita
mucho
en
esta
imagen
o
algo
que
se
repita
en
este
grupo
de
imágenes
y
después
en
una
segunda
etapa
lo
que
vamos
a
hacer
si
presentamos
una
vaca
a
ver
bueno
qué
es
es
un
carro
o
una
vaca
.
entonces
nos
va
a
dar
una
probabilidad
o
un
grado
para
saber
si
es
un
carro
o
una
vaca
.
esa
es
básicamente
la
idea
de
la
automática
ok
entonces
este
qué
es
importante
en
sistemas
es
que
tenemos
que
tener
un
conjunto
de
imágenes
que
fueron
anotadas
manualmente
y
son
la
base
de
nuestro
aprendizaje
.
esto
puede
parecer
primero
simple
pero
como
nos
vamos
a
basar
en
imágenes
como
vamos
a
tratar
de
generalizar
es
bastante
dependiente
a
lo
que
uno
aprende
.
si
uno
muestra
cierto
tipo
de
imágenes
la
computadora
va
a
conseguir
una
generalización
bastante
grande
basada
en
lo
que
presentamos
.
por
ejemplo
si
yo
presento
estos
y
le
digo
a
la
computadora
qué
bueno
cómo
hace
uno
para
aprender
.
de
repente
lo
muestro
acá
si
uno
cómo
hace
uno
para
aprender
que
esto
son
vacas
.
yo
si
fuese
la
computadora
digo
mira
fíjense
en
la
esquina
derecha
abajo
siempre
es
verde
.
ok
entonces
si
yo
veo
una
imagen
donde
abajo
a
la
derecha
es
verde
es
que
tengo
una
vaca
.
entonces
el
hecho
de
elegir
la
información
es
bastante
es
bastante
importante
y
es
bastante
complicado
.
y
si
se
hace
muy
muy
general
entonces
no
aprendemos
nada
tampoco
.
ok
entonces
todo
esto
es
un
tema
de
investigación
que
no
no
voy
a
hablar
mucho
en
en
esta
charla
no
.
pero
se
lo
quería
lo
quería
tener
presente
ok
aquí
el
número
de
clasificadores
que
vamos
a
tener
es
del
tamaño
del
diccionario
.
o
sea
que
para
cada
vocablo
que
uno
quiere
nuevo
vamos
a
tener
que
aprender
un
clasificador
nuevo
por
ejemplo
si
es
un
SVM
vamos
a
poner
un
SVM
si
es
no
sé
qué
vamos
a
tener
uno
nuevo
y
puede
ser
hasta
un
grupo
de
clasificadores
por
cada
concepto
que
vamos
a
querer
aprender
.
este
para
ustedes
que
trabajan
si
trabajan
con
cosas
lingüísticas
y
tal
en
el
caso
de
multimedia
en
el
caso
de
estudios
de
este
tipo
no
hay
relación
entre
las
palabras
.
si
no
hay
en
general
hay
muy
pocos
trabajos
en
los
cuales
efectivamente
se
aprende
y
se
aprende
por
ejemplo
las
relaciones
al
mismo
tiempo
entre
los
diferentes
conceptos
.
entonces
bueno
simplemente
es
plano
un
diccionario
plano
de
conceptos
bastante
simples
y
gente
que
estudia
cómo
vamos
a
hacer
para
elegir
los
conceptos
que
queremos
.
y
que
podemos
aprender
entonces
cuál
es
el
problema
más
grande
que
tenemos
porque
puede
parecer
claro
si
vemos
lo
que
lo
que
teníamos
hace
un
segundo
este
problema
les
parece
bastante
simple
a
ustedes
.
lo
que
pasa
es
que
la
computadora
yo
no
le
puedo
presentar
la
imagen
tal
cual
sino
que
tengo
que
transformar
esta
imagen
en
un
vector
que
va
a
representar
esta
imagen
dentro
de
la
computadora
.
y
al
representar
esto
lo
que
yo
tengo
a
mano
es
la
señal
que
es
píxel
por
píxel
y
tengo
el
color
básicamente
de
cada
uno
de
los
puntos
porque
eso
es
así
que
nosotros
podemos
representar
la
imagen
en
la
computadora
.
y
el
de
un
lado
tenemos
esta
representación
que
es
un
vector
imagínense
ustedes
un
vector
y
del
otro
lado
tengo
una
imagen
.
la
imagen
nosotros
la
podemos
representar
muy
bien
y
podemos
analizarla
como
seres
humanos
y
de
por
el
otro
lado
el
vector
no
lo
podemos
entender
y
la
computadora
parece
que
tampoco
.
y
la
diferencia
entre
estos
dos
extremos
es
lo
que
llamo
el
semantic
gap
que
ya
oímos
esta
noción
esta
mañana
no
.
entonces
qué
es
lo
que
podemos
extraer
de
las
imágenes
.
bueno
de
los
píxel
podemos
sacar
píxel
por
píxel
podemos
sacarle
el
color
.
después
viendo
cómo
se
comporta
un
píxel
con
otro
por
ejemplo
si
se
repiten
podemos
ver
si
hay
textura
si
hay
algo
que
se
repite
de
manera
horizontal
tipo
una
cebra
entonces
tenemos
una
textura
no
.
y
podemos
descubrir
otro
tipo
de
cosas
como
formas
y
tal
.
esto
lo
tenemos
que
meter
en
un
espacio
numérico
para
poder
hacer
comparaciones
.
y
este
y
el
problema
que
vamos
a
tener
es
que
como
para
poder
asociar
estas
dos
cosas
.
y
eso
es
lo
que
vamos
a
hacer
con
el
aprendizaje
automático
tratar
de
conseguir
regularidad
en
el
vector
para
analizar
.
ok
entonces
les
voy
a
mostrar
para
para
mostrarles
qué
pasa
si
uno
se
fija
solamente
en
el
vector
.
por
ejemplo
esto
es
una
descripción
esta
imagen
esta
imagen
y
todas
estas
imágenes
tienen
la
misma
descripción
de
color
de
proporción
de
colores
.
tenemos
la
misma
cantidad
de
amarillo
la
misma
cantidad
de
negro
la
misma
cantidad
de
rojo
pero
semánticamente
no
tienen
nada
que
ver
.
esto
es
exactamente
el
problema
del
semantic
gap
que
de
un
lado
tenemos
la
descripción
numérica
que
nos
da
la
proporción
de
color
y
del
otro
lado
tenemos
una
cosas
que
son
completamente
interpretadas
de
otra
manera
además
en
un
en
cada
vez
en
un
contexto
diferente
.
ok
ok
entonces
una
de
las
ideas
de
para
poder
hacer
un
clasificador
un
clasificador
de
este
tipo
un
poco
más
inteligente
es
tratar
de
destructurar
o
de
sacar
de
este
de
este
documento
o
de
este
de
este
del
documento
perdón
de
este
documento
es
de
tratar
de
descomponerlo
y
tratar
de
sacar
palabras
.
por
qué
porque
en
esta
imagen
tenemos
muchas
cosas
tenemos
la
vaca
tenemos
un
poco
de
hierba
o
grama
en
español
.
en
Venezuela
no
se
dice
grama
y
tenemos
un
poco
de
cielo
entonces
la
idea
es
tratar
de
crear
un
diccionario
automáticamente
que
nos
va
a
permitir
a
descubrir
las
palabras
que
están
dentro
de
la
imagen
.
ok
entonces
por
ejemplo
si
tenemos
esta
imagen
lo
que
podemos
hacer
es
segmentarla
de
alguna
manera
automática
y
cortar
esta
flores
y
después
dejar
el
fondo
y
decir
que
eso
es
no
sé
un
arbusto
.
eso
se
puede
hacer
automáticamente
pero
se
ha
descubierto
que
el
la
el
la
segmentación
inteligente
no
mejora
mucho
los
resultados
a
comparación
a
una
segmentación
bastante
simple
que
sería
una
segmentación
de
este
tipo
.
ok
entonces
lo
que
se
hace
es
podemos
segmentar
esto
en
pequeños
cuadraditos
y
tratar
de
aprender
después
qué
es
qué
es
cada
cuadradito
no
.
en
el
caso
del
del
primer
problema
que
teníamos
del
semantic
gap
qué
hacíamos
.
cerrábamos
la
imagen
la
transformábamos
en
un
vector
que
puede
ser
un
histograma
por
ejemplo
de
color
y
de
textura
y
claro
la
información
se
nos
perdía
un
poco
dentro
de
este
vector
.
ahora
lo
que
vamos
a
hacer
es
segmentar
la
imagen
sacar
varios
cuadraditos
y
cada
cuadradito
lo
vamos
a
poder
clasificar
y
decir
ok
esto
es
una
flor
esto
es
hierba
esto
es
tal
cosa
y
hacer
un
descriptor
visual
.
ok
el
problema
del
semantic
gap
no
fue
resuelto
completamente
yo
no
les
voy
a
decir
que
claro
si
yo
veo
esto
igual
voy
a
tener
si
yo
veo
si
yo
tengo
un
vector
si
yo
tengo
esta
descripción
igual
voy
a
tener
un
vector
.
o
sea
que
igual
el
semantic
gap
está
pero
como
que
comprimiéndose
haciendo
una
un
clustering
.
bueno
es
un
clustering
un
poco
simple
pero
se
es
tratando
de
focalizar
el
algoritmo
en
pequeños
espacios
esto
nos
permite
de
como
que
descomponer
el
problema
del
gap
.
no
del
en
en
vez
de
tratar
de
saltar
el
gap
completo
atravesarlo
completo
lo
que
hacemos
es
tratarlo
de
pasarlo
por
por
pasos
.
ok
aquí
pueden
aparecer
bastantes
problemas
por
ejemplo
la
anotación
que
teníamos
hace
un
segundo
era
una
anotación
a
nivel
global
de
la
imagen
.
claro
decíamos
bueno
ahí
hay
una
flor
ahora
aquí
no
te
no
se
sabe
dónde
dónde
está
la
flor
dónde
está
la
la
dónde
está
la
parte
de
atrás
entonces
hay
que
hacer
una
anotación
un
poco
más
precisa
.
o
tratar
de
aprender
a
pesar
del
hecho
que
uno
no
sabe
.
ahora
lo
que
yo
les
voy
a
mostrar
es
simplemente
cuando
uno
sabe
el
caso
donde
uno
sabe
que
esto
es
una
flor
y
que
no
es
una
flor
.
y
el
truco
para
pasar
de
del
caso
del
de
lo
que
le
voy
a
presentar
a
ustedes
al
caso
donde
no
se
sabe
es
tratando
de
hacer
lo
mismo
que
se
hace
en
siempre
con
el
aprendizaje
artificial
tratar
de
ver
cuando
algo
se
repite
muy
a
menudo
o
una
algo
que
se
repite
bueno
se
hace
esa
hipótesis
que
si
algo
me
aparece
muchas
veces
verde
verde
verde
verde
verde
entonces
digamos
y
y
otros
colores
vamos
a
decir
que
lo
que
es
más
frecuente
es
justamente
por
ejemplo
árbol
o
hierba
.
ok
y
vamos
a
botar
el
el
ruido
de
las
palabras
que
fueron
mal
asociadas
ok
pero
eso
no
lo
vamos
a
ver
sino
vamos
a
ver
simplemente
asumiendo
que
yo
sé
que
esto
es
que
yo
sé
qué
qué
cuadradito
es
qué
.
entonces
cómo
va
a
funcionar
esto
.
a
ver
cómo
va
a
funcionar
.
vamos
a
tener
una
bolsa
donde
vamos
a
tener
flores
de
diferentes
colores
ok
.
entonces
aquí
lo
que
lo
que
pasa
es
como
vamos
a
tener
unos
ejemplos
ya
sabemos
que
cada
cuadradito
es
una
flor
.
pero
qué
pasa
las
flores
pueden
ser
de
muchos
colores
pueden
ser
amarillas
pueden
ser
rojas
pueden
ser
de
cualquier
color
.
y
lo
que
tenemos
que
hacer
es
tratar
de
hacer
un
poco
lo
que
hace
la
gente
cuando
trabaja
con
el
texto
tratar
de
de
conseguir
grupos
de
algo
como
grupo
de
sinónimos
del
mismo
sentido
.
como
aquí
estamos
trabajando
más
bien
en
algo
visual
lo
que
vamos
a
tratar
de
hacer
es
hacer
un
clustering
lo
que
presentaba
Andreas
hace
un
segundo
pero
no
aplicado
a
la
información
a
los
documentos
a
los
ficheros
de
manera
general
pero
si
no
aquí
aplicado
a
la
descripción
de
los
pequeños
patches
de
los
pequeños
parches
traducción
de
patches
de
parches
de
las
imágenes
no
.
y
así
vamos
a
poder
separar
en
pequeños
grupos
y
y
elegir
un
representante
de
cada
de
estos
grupos
para
poder
después
hacer
un
razonamiento
basado
en
casos
por
ejemplo
.
ok
entonces
cuál
es
la
idea
del
clustering
.
es
reducir
el
tamaño
del
vocabulario
que
es
un
poco
lo
que
les
decía
elegir
un
poco
un
grupo
de
sinónimos
es
decir
todas
las
flores
rojas
.
bueno
ese
es
un
concepto
ese
es
como
que
un
sentido
pues
todas
las
rojas
amarillas
eso
es
otro
sentido
ok
y
además
lo
que
nos
va
a
permitir
es
que
si
nos
aparecen
cosas
raras
o
que
están
mal
anotadas
por
ejemplo
algo
verde
o
algo
se
va
a
perder
porque
lo
que
vamos
a
conseguir
son
los
grandes
grupos
y
vamos
a
elegir
un
representante
de
un
grupo
que
sea
bastante
grande
.
ok
bueno
a
ver
.
ok
entonces
estos
son
unos
experimentos
que
hicimos
que
hice
con
Andreas
y
un
estudiante
que
está
haciendo
un
doctorado
donde
Andreas
y
básicamente
la
técnica
para
construir
el
diccionario
es
la
utilización
de
un
clustering
bastante
simple
.
y
para
clasificar
es
un
classifier
que
es
un
clasificador
muy
muy
simple
.
la
idea
es
de
conseguir
un
ejemplo
no
si
yo
tengo
un
cuadradito
que
es
rojo
bueno
vamos
a
ver
déjame
ver
si
tengo
un
cuadradito
rojo
y
veo
de
qué
clase
es
.
si
es
una
flor
digo
ok
genial
es
una
flor
ese
es
el
un
neighbour
classifier
.
y
claro
como
uno
se
puede
equivocar
porque
puede
tener
ruido
entonces
uno
hace
un
o
sea
busca
cuatro
vecinos
cuatro
cosas
que
se
parecen
y
veo
ah
si
tres
me
dicen
que
esto
es
flor
debe
ser
que
es
flor
.
ok
es
el
la
técnica
bastante
simple
utilizamos
una
base
de
imágenes
bastante
pequeña
hay
que
decir
para
para
el
tipo
de
de
experimentos
o
sea
para
este
tipo
de
experimentos
está
bien
pero
para
retrieval
en
general
esto
es
aprendizaje
de
anotaciones
de
seiscientas
imágenes
y
había
veintiún
conceptos
.
estas
imágenes
fueron
segmentadas
no
sé
por
quién
la
verdad
que
no
sé
quién
las
segmentó
pero
nos
permite
automáticamente
de
saber
qué
clase
es
qué
clase
es
cada
cuadradito
.
podemos
saber
si
es
la
vaca
o
es
la
grama
o
es
el
carro
ok
teníamos
sesenta
por
ciento
entonces
para
poder
evaluar
nuestro
trabajo
qué
hacemos
.
aprendemos
con
una
parte
la
base
y
hacemos
tests
con
una
parte
completamente
separada
de
la
base
para
poder
ver
si
lo
generalizamos
.
por
qué
porque
si
usamos
la
misma
parte
de
aprendizaje
para
el
test
lo
que
va
a
hacer
la
la
computadora
es
aprender
de
memoria
porque
las
las
computadoras
tienen
un
poco
tendencia
a
aprenderse
todo
de
memoria
porque
es
lo
más
fácil
.
se
aprende
que
si
el
píxel
este
aquí
y
el
píxel
este
de
aquí
valía
tanto
y
tanto
entonces
es
un
carro
.
y
eso
no
es
lo
que
queremos
nosotros
queremos
es
aprender
una
generalización
hay
que
separar
el
aprendizaje
y
el
test
para
poder
aprender
un
poco
mejor
.
entonces
este
los
resultados
aquí
tenemos
o
sea
puse
algunas
clases
para
que
para
que
uno
vea
basical
book
car
grass
sky
tree
y
water
.
y
qué
podemos
ver
bueno
podemos
ver
que
la
precisión
de
los
cuadraditos
es
bastante
alta
no
.
tenemos
la
precisión
local
o
sea
viendo
cuadraditos
nada
más
es
mucho
más
alta
que
la
precisión
usando
un
sistema
global
.
qué
quiere
decir
que
cuando
qué
es
la
precisión
que
cuando
nosotros
decimos
que
es
esto
es
tal
cosa
eso
quiere
decir
que
sí
es
.
entonces
genial
no
entonces
bueno
nos
parece
vamos
bien
pero
por
el
otro
lado
qué
pasa
si
nos
fijamos
en
el
recall
tenemos
lo
contrario
que
cada
vez
que
vemos
un
cuadradito
a
veces
por
ejemplo
de
todos
los
cuadraditos
que
teníamos
en
la
base
que
no
sé
cuántos
deberían
ser
bastantes
porque
seiscientos
por
el
número
de
cuadrados
por
imágenes
hay
muchos
muchos
cuadrados
que
nosotros
no
supimos
reconocer
.
que
dijimos
debe
ser
otra
cosa
y
no
sé
qué
entonces
este
efecto
es
bastante
interesante
.
y
qué
qué
va
a
pasar
lo
que
vamos
a
hacer
es
que
lo
que
sabemos
es
que
los
detectores
de
este
tipo
son
muy
especializados
saben
bien
detectar
y
cuando
dicen
que
está
bueno
está
bueno
.
ok
pero
no
saben
siempre
ahora
el
truco
va
a
ser
que
como
en
la
imagen
vamos
a
tener
muchos
lugares
vamos
a
tener
varios
lugares
vamos
a
decir
que
esto
fue
flor
esto
es
flor
esto
es
flor
y
esto
es
hierba
esto
es
hierba
pero
hay
unos
que
no
que
no
vamos
a
hacer
el
recall
o
sea
no
lo
vamos
a
detectar
y
básicamente
de
alguna
manera
hay
que
decir
por
los
sistemas
de
voto
por
ejemplo
adivinar
si
es
o
no
.
eso
es
lo
que
voy
a
explicar
ahora
un
poco
más
con
detalle
.
pero
antes
para
poder
comparar
bien
las
diferentes
el
comportamiento
de
este
tipo
de
de
sistemas
pero
de
manera
un
poco
más
global
tenemos
que
combinar
la
precisión
y
el
el
recall
.
pero
recall
en
español
era
el
la
cobertura
y
podemos
ver
que
por
ejemplo
cosas
tipo
como
sky
funciona
es
es
genial
o
sea
esto
es
para
detectar
el
cielo
es
muy
bueno
.
por
qué
porque
el
cielo
tiene
poca
variabilidad
o
sea
en
general
el
cielo
o
es
bastante
uniformemente
azul
o
bastante
uniformemente
blanco
pero
básicamente
dentro
de
dos
o
tres
clases
es
bastante
uniforme
.
y
entonces
este
tipo
de
técnica
funciona
muy
bien
ahora
si
uno
elige
algo
como
un
pájaro
el
problema
se
complica
no
.
porque
la
variabilidad
dentro
de
la
clase
pájaro
es
muy
muy
muy
grande
.
ahora
tenemos
cosas
que
pueden
sorprender
un
poco
por
ejemplo
si
vemos
la
clase
building
que
son
edificios
a
uno
le
parece
que
todos
los
edificios
se
parecen
.
bueno
la
verdad
es
que
no
la
verdad
es
que
acá
los
edificios
son
bastante
diferentes
y
este
sistema
no
da
muy
buenos
resultados
.
pero
claro
es
basado
esta
conclusión
es
basada
en
un
ejemplo
en
un
experimento
.
ok
así
que
pero
de
manera
general
flores
hierba
vías
todo
lo
que
son
descripciones
de
superficies
de
la
imagen
funcionan
bastante
bien
.
y
es
bastante
lógico
ok
ahora
este
no
el
estudiante
Cristian
Cristian
desarrolló
un
sistema
entonces
se
lo
voy
a
mostrar
espero
que
funcione
.
ok
.
entonces
este
sistema
lo
fue
desarrollado
en
la
en
la
universidad
de
OttovonGuericke
.
y
aquí
les
vamos
a
mostrar
yo
les
voy
a
mostrar
solamente
si
logro
hacerlo
.
a
ver
no
nos
interesa
el
principio
.
esto
pero
es
para
mostrarles
a
ustedes
un
poco
la
la
la
calidad
de
la
el
problema
que
yo
tengo
en
la
pantalla
no
.
lo
veo
difícil
.
para
el
micro
acá
.
no
no
pero
yo
puedo
hacer
con
los
dos
aló
el
problema
es
que
el
problema
es
que
yo
quería
skip
y
quería
pasarlo
en
full
screen
pero
en
pantalla
completa
y
quería
pasar
skip
pero
mi
pantalla
no
está
cortada
entonces
no
tengo
la
no
puedo
tocar
al
play
.
a
ver
a
ver
a
ver
bueno
no
importa
puedo
hablar
por
acá
.
ok
esta
es
la
parte
de
segmentación
que
se
puede
hacer
en
el
sistema
manual
pero
yo
no
quería
mostrarle
esto
a
ustedes
sino
que
le
iba
a
quería
mostrarles
el
la
parte
de
.
a
ver
yo
tengo
una
idea
va
a
durar
un
poco
pero
bueno
.
la
mejor
idea
es
esta
.
esta
es
la
mejor
idea
ok
ah
.
ok
ok
.
ya
está
entonces
esto
es
la
ahora
sí
a
ver
.
funciona
ok
.
está
está
funcionando
verdad
entonces
aquí
bueno
podemos
ver
bueno
me
quedo
sentado
aquí
podemos
ver
entonces
el
sistema
buscamos
una
flor
entonces
podemos
conseguir
imágenes
que
tienen
flores
y
lo
que
podemos
ver
es
que
que
la
computadora
detecta
flores
pero
también
detecta
pequeños
patches
donde
se
equivoca
.
en
la
parte
de
abajo
donde
dice
anotation
podemos
ver
qué
fue
lo
que
fue
detectado
en
el
cuadradito
por
donde
está
pasando
el
mouse
no
.
el
mouse
está
pasando
por
aquí
arriba
ahí
lo
pueden
ver
y
entonces
abajo
aparece
la
anotación
en
la
zona
inferior
central
aparece
que
es
flower
que
no
que
es
flower
.
aquí
de
repente
detectó
una
vaca
por
ejemplo
aquí
detectó
a
un
árbol
ok
pero
se
pueden
fijar
que
la
mayoría
de
los
de
las
palabras
o
sea
de
los
tags
que
fueron
descubiertos
son
tags
de
la
mayoría
son
correctos
.
pero
hay
varios
que
se
equivoca
no
y
parece
bastante
impresionante
y
ese
es
justamente
el
problema
del
gap
semántico
.
lo
único
que
aquí
hemos
resuelto
un
poco
el
problema
y
tratamos
de
evitar
el
ruido
.
aquí
bicicleta
funciona
bastante
bien
tenemos
road
fue
detectado
también
y
bueno
tenemos
a
veces
algunos
errores
tipo
water
tree
ship
y
tal
ok
.
bueno
ok
a
ver
ahora
para
seguir
en
la
presentación
don't
save
.
ok
.
entonces
a
partir
a
partir
.
ok
entonces
a
partir
de
estas
indexaciones
ahora
uno
puede
uno
tiene
qué
tenemos
.
una
imagen
y
dentro
de
cada
imagen
tenemos
como
que
detectamos
varias
cosas
.
que
si
perro
flor
y
tal
y
tenemos
la
mayoría
de
las
de
las
de
la
de
las
cosas
que
detectamos
que
son
en
general
en
mayoría
son
las
que
queremos
verdad
.
entonces
bueno
podemos
inventar
un
sistema
muy
fácil
seguimos
ok
si
a
partir
de
cierto
cantidad
de
imágenes
a
a
cierto
cantidad
de
cuadraditos
tenemos
tal
concepto
entonces
por
sistema
de
voto
decimos
está
bien
.
es
tenemos
una
flor
vimos
que
hay
no
sé
treinta
cuadraditos
o
una
proporción
y
por
lo
tanto
debe
ser
una
flor
.
podemos
hacer
algo
tipo
una
region
based
que
es
fijarse
en
alrededor
si
tenemos
alrededor
qué
sé
yo
tenemos
que
es
flor
flor
flor
flor
flor
y
en
centro
tenemos
una
vaca
podemos
decir
o
cualquier
cosa
podemos
decir
no
debe
ser
un
error
que
es
como
que
es
pasar
como
un
filtro
encima
de
la
imagen
para
poder
filtrar
esto
.
ahora
de
esto
no
les
voy
a
explicar
porque
eso
son
como
que
técnicas
.
lo
que
sí
puede
ser
muy
interesante
y
se
hace
es
considerar
esto
verdaderas
palabras
.
que
es
decir
transformar
esto
en
un
vector
en
un
vector
como
si
fuese
un
diccionario
de
lo
más
normal
y
tratar
de
conseguir
otro
documento
con
las
mismas
técnicas
que
uno
consigue
documentos
de
en
el
en
el
sistema
texto
.
ahora
se
lo
que
se
hace
básicamente
es
algo
tipo
.
por
qué
porque
vamos
a
tener
muchos
flor
flor
flor
flor
flor
entonces
vamos
a
pensar
este
documento
sí
debe
hablar
de
flor
y
bueno
de
vez
en
cuando
sale
algo
.
hay
que
un
poco
hay
que
cambiar
un
poco
la
idea
de
los
errores
.
hay
que
hacer
un
un
poco
cambiar
la
idea
del
normal
por
qué
porque
claro
lo
en
un
texto
cuando
yo
pongo
una
palabra
que
es
bastante
rara
y
me
sale
en
alguna
parte
me
interesa
que
me
aparezca
este
documento
.
en
este
caso
es
un
poco
diferente
yo
no
quiero
que
si
tengo
no
sé
de
repente
tengo
una
bicicleta
dentro
de
un
lago
entonces
yo
no
quiero
que
me
aparezca
.
yo
pienso
que
en
este
en
este
este
tipo
de
de
cosas
hay
bastantes
bastantes
posibilidades
de
hacer
trabajos
sobre
tipo
de
de
lingüística
de
trabajo
natural
processing
language
.
por
qué
porque
aquí
podemos
tratar
de
tener
las
relaciones
entre
los
diferentes
conceptos
.
por
ejemplo
si
hay
agua
si
hay
tal
cosa
que
todo
esto
tiene
que
tener
alguna
lógica
a
un
nivel
un
poco
más
abstracto
.
yo
no
conozco
mucho
de
natural
processing
pero
me
parece
es
una
gran
oportunidad
.
por
qué
me
parece
una
oportunidad
porque
es
muy
funciona
muy
bien
del
en
una
manera
naive
o
sea
simplemente
transformando
esto
en
un
diccionario
funciona
muy
bien
.
porque
eso
fue
este
esto
es
la
técnica
la
técnica
de
los
cinco
mejores
puede
ser
que
no
los
cinco
cuatro
de
los
cinco
mejores
sistemas
de
dos
mil
ocho
que
se
acaba
de
presentar
hace
hace
dos
semanas
.
es
exactamente
lo
que
les
acabo
de
contar
ahora
lo
que
cambia
es
que
no
se
utilizó
no
se
utilizó
como
descriptor
el
color
.
lo
que
se
descriptó
se
utilizó
fue
que
es
una
técnica
bastante
que
es
bastante
además
ya
la
veremos
un
poco
más
adelante
pero
una
técnica
nueva
que
está
bastante
de
moda
que
permite
conseguir
los
puntos
que
son
bastante
discriminantes
que
permiten
escribir
en
en
en
la
pantalla
.
entonces
igual
a
partir
de
esos
puntos
hacemos
un
diccionario
basado
en
un
clustering
y
hacemos
un
diccionario
tipo
texto
y
con
eso
lo
que
vamos
a
hacer
es
tratar
de
detectar
y
buscar
conceptos
.
funciona
bastante
bien
ahora
cuando
digo
bastante
bien
es
que
son
los
mejores
del
mundo
los
que
tienen
los
mejores
resultados
en
la
competición
.
esto
da
un
average
precision
o
sea
da
un
el
promedio
de
el
de
la
precisión
promedio
no
.
o
sea
el
promedio
sobre
todos
los
conceptos
que
tenemos
sobre
la
precisión
promedio
cuando
vemos
los
resultados
que
obtenemos
en
una
lista
.
y
es
más
o
menos
de
oscila
entre
cero
coma
cero
siete
para
los
conceptos
los
más
difíciles
que
puede
ser
por
ejemplo
goverment
leader
que
es
bastante
difícil
de
detectar
a
hasta
cero
coma
tres
por
ejemplo
si
queremos
detectar
un
terreno
de
basketball
.
no
aquí
bueno
esto
es
el
gráfico
típico
por
ejemplo
si
queremos
detectar
en
en
tenemos
aquí
de
perdón
siempre
lo
mismo
.
de
aquí
en
en
rojo
tenemos
este
por
ejemplo
si
vemos
algo
como
maps
para
ver
si
es
que
estamos
viendo
en
la
pantalla
un
maps
bastante
alto
para
ver
si
es
el
bastante
alto
.
por
qué
porque
esto
es
sobre
imágenes
de
video
entonces
es
la
presentación
del
video
que
es
bastante
característica
y
se
repite
bastante
y
siempre
muy
regularmente
se
parece
.
este
y
pero
se
complica
por
ejemplo
si
buscamos
que
es
police
security
corporate
leader
por
ejemplo
.
ok
ahora
entonces
si
esto
funciona
bastante
bien
pero
tenemos
el
problema
del
diccionario
o
sea
cuántas
palabras
vamos
a
hacer
.
los
mejores
equipos
del
mundo
que
prometían
que
para
este
año
íbamos
a
tener
varios
miles
de
palabras
de
conceptos
bueno
actualmente
van
por
trescientos
setenta
y
cuatro
.
o
sea
el
diccionario
actual
visual
es
de
trescientos
setenta
y
cuatro
palabras
.
y
fue
propuesto
es
basado
en
una
antología
que
tiene
creo
que
son
mil
y
se
eligieron
trescientos
setenta
y
cuatro
que
funcionan
más
o
menos
decentemente
.
ok
pero
a
pesar
de
todo
yo
pienso
que
estos
conceptos
se
pueden
utilizar
se
pueden
utilizar
para
mejorar
la
busca
de
información
basada
en
texto
.
porque
el
texto
funciona
muy
bien
es
muy
semántico
por
qué
es
semántico
porque
cada
una
de
las
palabras
tiene
un
significado
cuando
hacemos
la
representación
dentro
de
la
computadora
vamos
a
hacer
una
representación
también
vectorial
.
pero
cada
los
cada
uno
de
las
dimensiones
tiene
un
significado
es
si
vamos
a
y
hacemos
un
semantic
indexing
siguen
teniendo
aunque
no
es
una
palabra
concreta
vamos
a
tener
dentro
de
de
cada
dimensión
va
a
tener
un
significado
bastante
concreto
.
entonces
este
qué
es
la
proposición
que
que
hacemos
aquí
.
es
la
idea
de
utilizar
el
texto
y
después
botar
las
imágenes
que
nos
molestan
que
no
corresponden
a
lo
visual
.
este
un
un
ejemplo
de
un
ejemplo
de
de
este
tipo
de
de
ideas
es
lo
que
les
contaba
al
principio
.
si
tenemos
un
sistema
de
búsqueda
por
ejemplo
que
estamos
buscando
imágenes
de
productos
yo
les
decía
claro
el
producto
lo
puedo
conseguir
por
la
descripción
del
texto
.
pero
en
el
texto
me
va
a
aparecer
el
hecho
que
ese
producto
es
amarillo
azul
o
algo
.
entonces
si
yo
puedo
combinar
estas
dos
informaciones
viendo
la
imagen
veo
que
es
azul
y
viendo
el
texto
veo
que
es
una
cartera
Nike
.
entonces
puedo
saber
que
me
puedo
saber
que
la
imagen
o
puedo
apostar
que
la
imagen
es
una
imagen
de
una
cartera
azul
de
Nike
.
ok
ese
tipo
de
cosas
nosotros
hicimos
en
el
dos
mil
dos
un
sistema
de
venta
online
para
prototipo
no
.
de
de
para
buscar
productos
y
y
y
bueno
yo
no
sé
si
lo
tengo
acá
.
es
un
sistema
así
de
productos
.
aquí
tuvimos
que
separar
el
las
dos
nociones
para
para
bien
separar
en
la
demostración
para
poder
mostrar
que
si
uno
lo
busca
en
el
texto
no
funciona
y
si
uno
lo
busca
texto
con
imagen
junto
pero
básicamente
por
ejemplo
esto
es
la
búsqueda
de
de
un
de
una
camiseta
morada
por
ejemplo
.
y
es
bastante
eficaz
ese
tipo
de
noción
ok
este
ese
tipo
de
idea
también
en
el
en
el
sistema
también
lo
teníamos
.
pero
es
una
una
idea
que
puede
ser
es
bastante
interesante
por
ejemplo
es
la
utilización
de
detector
de
caras
.
por
qué
porque
detectar
caras
es
bastante
simple
pero
y
se
puede
utilizar
más
de
manera
bastante
inteligente
.
por
ejemplo
hoy
vimos
una
presentación
donde
se
utilizaba
la
detectamos
que
hay
nombres
propios
por
ejemplo
.
se
puede
combinar
si
sabemos
que
es
nombre
propio
probablemente
lo
que
queremos
ver
es
la
imagen
de
esa
persona
entonces
podemos
combinar
el
hecho
que
sabemos
que
un
nombre
propio
en
la
en
la
pregunta
.
y
después
cuando
uno
busca
la
la
cuando
uno
tiene
la
imagen
selecciona
simplemente
las
imágenes
donde
sabemos
que
tenemos
una
cara
.
ok
bueno
ese
tipo
de
cosas
se
hacen
hoy
en
día
hay
bastantes
sistemas
punto
com
es
uno
de
venta
online
tenemos
punto
com
que
propuso
el
de
primero
la
búsqueda
de
imágenes
basada
con
filtro
.
que
uno
lo
tiene
pero
el
filtro
lo
tiene
que
hacer
en
postproceso
no
lo
hace
automáticamente
.
lo
mismo
hace
Google
que
lo
puso
una
semana
más
tarde
y
este
y
perdón
.
y
la
idea
es
ahora
.
y
bueno
y
eso
funciona
bastante
bien
por
qué
porque
estos
dos
detectores
son
bastante
visuales
el
hecho
de
conseguir
caras
o
conseguir
colores
es
bastante
visual
entonces
todavía
no
nos
atrevemos
mucho
a
hacer
el
salto
del
semantic
gap
aquí
es
un
saltito
no
.
simplemente
decimos
ah
azul
bueno
entonces
detectamos
acá
azul
que
no
es
tan
trivial
porque
los
colores
pueden
estar
por
ejemplo
el
blanco
si
hay
sombra
o
si
hay
iluminación
de
fotografía
puede
no
ser
tan
blanco
por
ejemplo
entonces
el
salto
puede
ser
un
poquito
más
largo
de
lo
que
uno
piensa
.
pero
en
fin
lo
que
queríamos
ver
acá
es
cómo
podemos
utilizar
este
el
utilizar
conceptos
un
poco
de
nivel
más
alto
o
sea
conceptos
del
tipo
de
los
que
acabamos
de
ver
para
mejorar
una
búsqueda
de
información
texto
.
entonces
esto
es
son
resultados
que
utilizamos
de
que
organizó
Paul
esta
mañana
.
y
este
la
idea
va
a
ser
agarrar
un
topic
que
esto
eran
los
topics
.
por
ejemplo
teníamos
que
hay
que
buscar
que
y
las
relevant
images
will
show
.
o
sea
las
imágenes
pertinentes
nos
van
a
mostrar
focas
que
de
aquí
hay
varios
ejemplos
de
focas
.
y
nos
va
a
mostrar
un
poco
de
agua
que
puede
ser
el
mar
un
lago
.
pero
las
imágenes
que
no
son
relevantes
este
dónde
es
.
imágenes
de
focas
con
no
agua
con
no
agua
visible
en
la
imagen
no
son
pertinentes
para
nuestro
problema
ok
.
uno
tiene
derecho
nosotros
tenemos
derecho
de
utilizar
todo
este
esto
para
construir
la
pregunta
de
manera
automática
.
como
nosotros
no
sabemos
hacer
processing
automático
y
lenguaje
natural
lo
que
inventamos
que
fue
absolutamente
genial
ya
lo
verán
es
que
cuando
sale
not
dentro
de
la
frase
entre
dos
puntos
lo
borramos
y
lo
botamos
.
pero
esto
no
es
importante
para
el
problema
que
tenemos
acá
ok
.
lo
que
vamos
a
hacer
es
simplemente
transformar
este
topic
en
alguna
pregunta
texto
y
vamos
a
conseguir
imágenes
y
funciona
bastante
bien
.
y
después
vamos
a
tratar
de
detectar
a
partir
del
query
que
nos
interesa
un
concepto
que
que
ya
conocemos
de
nuestro
diccionario
de
trescientos
setenta
y
cuatro
palabras
y
tratar
de
utilizarlo
.
el
diccionario
este
de
nosotros
era
más
pequeño
porque
era
del
de
la
misma
competición
.
ok
y
después
aplicamos
el
detector
en
las
imágenes
y
decimos
sí
aquí
había
agua
no
aquí
no
había
esta
va
para
la
basura
.
ok
ese
es
el
concepto
de
la
de
este
de
este
de
de
este
del
del
método
.
entonces
para
para
poder
medir
qué
tan
bien
funciona
este
este
tipo
de
sistemas
este
trabajamos
con
diecisiete
conceptos
.
estos
conceptos
los
aprendimos
con
doscientos
con
dos
mil
imágenes
.
con
un
método
un
poco
diferente
del
que
presenté
hace
un
momento
utilizamos
árboles
de
decisión
.
y
para
poder
entrenar
la
esto
son
las
dos
dos
mil
imágenes
de
ejemplo
y
mil
imágenes
de
text
no
.
para
para
para
poder
aprender
la
generalización
después
en
el
challenge
en
el
en
el
desafío
de
búsqueda
de
imágenes
photo
retrieval
habían
veinte
mil
imágenes
que
eran
del
mismo
tipo
de
la
misma
familia
digamos
de
la
imágenes
que
teníamos
y
cada
imagen
tenía
texto
.
o
sea
tenía
una
descripción
como
la
que
acabamos
de
ver
y
era
semiestructurada
eso
no
se
utilizó
pero
bueno
tenía
.
y
cómo
vamos
a
a
cómo
se
se
probó
bueno
habían
treinta
y
nueve
topics
como
los
que
acabamos
de
ver
y
también
era
semiestructurado
.
y
habían
imágenes
ejemplos
también
para
el
que
quiera
participar
el
año
que
viene
habían
imágenes
ejemplos
que
nosotros
no
utilizamos
ok
.
es
para
darle
un
poco
el
el
peso
y
la
calidad
de
los
resultados
sabiendo
qué
tipo
en
qué
tipo
de
información
en
qué
tipo
de
data
hemos
trabajado
.
ok
el
tipo
de
conceptos
que
teníamos
era
conceptos
era
una
o
sea
era
una
un
grupo
de
conceptos
diecisiete
que
tenían
una
estructura
un
poco
jerárquica
.
son
conceptos
que
en
general
no
lo
elegimos
nosotros
los
eligieron
en
la
competición
que
son
bastante
simples
de
aprender
porque
son
los
que
funcionaban
bien
cuando
les
mostraba
el
ejemplo
hace
un
segundo
water
sky
day
road
building
mountain
etcétera
etcétera
no
.
son
ejemplos
que
funcionan
bastante
bien
y
la
descripción
que
nosotros
utilizamos
era
una
descripción
que
era
una
mezcla
de
descripción
global
y
local
.
porque
como
les
decía
bastante
interesante
ver
las
cosas
de
manera
local
porque
si
no
es
de
los
cuadraditos
como
lo
que
acabamos
de
ver
pero
tenemos
tenemos
rectángulos
que
nos
permiten
detectar
focalizar
la
atención
del
algoritmo
al
cielo
o
a
la
parte
superior
de
la
imagen
o
a
la
parte
inferior
de
la
imagen
o
el
centro
porque
son
son
lugares
donde
puede
aparecer
de
manera
regular
alguna
descripción
visual
y
de
ahí
podemos
aprender
.
el
sistema
de
aprendizaje
es
un
sistema
de
árboles
y
no
voy
a
entrar
mucho
en
detalles
pero
utilizamos
un
método
de
decision
trees
.
si
alguien
tiene
una
pregunta
me
puede
venir
a
ver
después
de
de
la
presentación
.
y
utilizamos
un
sistema
de
bagging
para
poder
tener
resultados
de
más
robustos
que
simplemente
utilizar
un
clasificador
único
.
entonces
se
combinan
varios
clasificadores
en
en
cadena
ok
entonces
el
texto
era
buscábamos
el
texto
como
un
muy
simple
.
y
para
construir
la
la
query
lo
que
hacíamos
en
este
experimento
particular
era
simplemente
agarramos
el
título
verdad
.
ok
y
después
utilizábamos
el
filtro
para
para
borrar
ok
una
de
las
grandes
preguntas
todo
esto
parece
bastante
simple
pero
una
de
las
grandes
preguntas
es
qué
concepto
vamos
a
utilizar
.
ok
porque
yo
tengo
seals
y
the
water
cómo
hago
yo
yo
para
saber
que
que
water
es
water
es
fácil
.
pero
para
saber
que
un
seals
es
un
animal
la
cosa
se
complica
.
ok
entonces
nosotros
hicimos
dos
métodos
para
poder
detectar
esto
.
un
método
es
simplemente
utilizamos
el
concepto
directamente
si
aparece
.
y
después
un
utilizamos
wordnet
porque
nosotros
no
sabemos
hacer
nada
más
complicado
que
eso
simplemente
wordnet
para
tratar
de
conseguir
sinónimos
y
tratar
de
ver
.
este
yo
no
les
voy
a
presentar
los
resultados
de
wordnet
aquí
para
no
complicar
la
presentación
.
pero
básicamente
lo
que
pasa
cuando
es
wordnet
que
las
asociaciones
que
uno
piensa
que
son
las
buenas
bueno
por
mala
suerte
a
veces
sí
a
veces
no
.
claro
en
el
caso
del
seal
funciona
perfecto
conseguimos
el
animal
.
pero
otro
de
los
topics
había
que
conseguir
straight
roads
que
eran
carreteras
derechas
.
y
straight
en
inglés
da
la
casualidad
que
uno
de
los
sinónimos
es
una
persona
que
no
es
homosexual
.
entonces
utilizamos
la
detección
de
personas
en
el
sistema
.
entonces
conseguimos
muchas
calles
donde
había
gente
parada
de
todo
tipo
.
ok
y
entonces
el
sistema
completamente
no
funcionó
entonces
globalmente
los
resultados
son
de
la
misma
calidad
que
no
utilizarlo
pero
sí
funciona
.
entonces
bueno
para
eso
se
puede
hacer
toda
una
discusión
y
nuevamente
me
parece
que
aquí
se
podría
hacer
algo
un
poco
más
inteligente
.
porque
si
ustedes
saben
que
straight
aquí
no
es
no
estamos
hablando
de
una
persona
sino
que
straight
es
describe
la
road
entonces
ustedes
pueden
saber
puede
ser
que
no
es
un
sinónimo
correcto
.
no
sé
en
fin
veamos
entonces
cómo
funciona
la
la
la
parte
del
filtro
.
entonces
ustedes
dicen
bueno
ok
ya
sabemos
que
seguro
es
agua
no
.
estamos
seguros
que
es
agua
cómo
vamos
a
hacer
ahora
qué
hacemos
problema
es
que
las
imágenes
que
vienen
con
el
texto
en
general
las
primeras
son
muy
buenas
en
general
.
entonces
si
el
mi
detector
que
ya
vimos
no
era
muy
bueno
dice
que
no
qué
hago
.
eso
se
puede
hacer
cálculo
probabilista
y
tal
no
sé
nosotros
lo
que
hicimos
es
simplemente
como
el
focus
de
la
métrica
y
eso
por
eso
que
hay
que
hacer
atención
en
las
competiciones
el
el
la
métrica
de
aquí
era
decir
que
las
primeras
lo
que
nos
interesa
son
las
primeras
veinte
imágenes
y
ver
cuál
es
la
precisión
en
veinte
.
básicamente
es
yo
le
doy
veinte
imágenes
de
las
veinte
cuántas
son
buenas
.
entonces
lo
que
nosotros
hicimos
es
simplemente
sacábamos
las
imágenes
que
no
correspondían
a
nuestro
criterio
ok
.
que
no
habían
que
no
tenían
el
concepto
visual
que
nosotros
queríamos
y
las
metíamos
en
el
rango
cincuenta
por
si
botábamos
las
primeras
cincuenta
no
.
y
así
regresan
por
que
así
no
porque
si
empezamos
a
traer
cosas
de
abajo
ahí
si
es
que
íbamos
probablemente
muy
mal
.
ok
entonces
cómo
funciona
esto
aquí
les
muestro
bueno
el
rango
uno
era
esto
no
había
una
una
una
foca
en
la
playa
había
un
poco
de
agua
detectamos
que
hay
agua
dijimos
ok
se
queda
bien
la
pegamos
a
la
segunda
hay
una
foca
no
hay
agua
no
la
queremos
la
metemos
en
el
rango
cincuenta
.
bien
llega
la
tres
tenemos
a
un
señor
y
detectamos
que
no
hay
agua
.
ahora
bastante
extraño
no
porque
problema
del
semantic
gap
no
en
la
primera
sí
habíamos
visto
el
agua
y
en
esta
no
vemos
el
agua
.
ok
pero
bueno
ese
es
el
precio
del
aprendizaje
automático
.
y
bueno
la
botamos
la
metemos
en
la
cincuenta
y
uno
por
si
exageramos
mucho
y
ella
regresa
no
.
y
bueno
y
así
va
el
sistema
hay
una
no
sé
qué
rango
es
esta
pero
bastante
alto
aparece
este
señor
no
sé
por
qué
aparece
ese
señor
pero
en
todo
caso
ese
señor
no
le
detectamos
agua
y
así
vamos
.
hasta
el
segundo
error
aparece
apenas
en
el
rango
veinte
de
este
sistema
.
o
sea
que
pueden
ver
que
con
un
concepto
tipo
agua
que
es
bastante
bueno
y
con
a
un
algo
un
concepto
textual
tipo
seal
que
también
es
bastante
bueno
desde
el
punto
de
vista
texto
podemos
funcionar
bastante
bien
.
ok
es
más
nosotros
éramos
un
poco
mejor
que
la
competición
porque
en
el
rango
ocho
nosotros
detectamos
que
esto
era
seal
que
había
agua
y
no
la
filtramos
pero
la
competición
nos
las
contó
como
mala
.
entonces
bueno
yo
ya
con
Paul
por
eso
que
yo
no
soy
muy
amigo
con
Paul
como
se
habrán
dado
cuenta
.
entonces
bueno
justamente
este
es
el
problema
o
sea
simplemente
para
decir
que
este
tipo
de
sistema
puede
funcionar
bastante
bien
el
hecho
de
traer
la
semántica
con
el
texto
y
filtrar
con
las
imágenes
.
ahora
esto
es
un
poco
un
poco
de
venta
entonces
veamos
mejor
un
poco
los
números
los
resultados
técnicos
.
entonces
lo
que
vemos
es
que
en
general
mejora
no
se
fijen
mucho
en
en
los
porcentajes
aunque
yo
los
dejé
porque
se
dejan
pero
el
porcentaje
no
es
porque
la
precision
es
bastante
baja
en
general
para
el
texto
puro
.
del
lado
del
lado
qué
del
lado
izquierdo
tenemos
para
los
treinta
y
nueve
topics
.
claro
de
los
treinta
y
nueve
como
el
sistema
no
es
no
usa
sinónimos
sino
simplemente
busca
el
topic
solamente
once
fueron
modificados
entonces
claro
siempre
se
mejora
.
o
sea
pase
lo
que
pase
si
mejoramos
de
este
lado
si
mejoramos
en
los
en
los
topics
que
modificamos
entonces
también
mejoramos
el
resultado
total
porque
las
otras
no
modificamos
.
entonces
vamos
a
fijarnos
simplemente
en
los
once
topics
que
si
en
los
en
las
si
las
once
preguntas
que
sí
funcionan
y
aquí
vemos
que
mejoramos
de
manera
digamos
relativa
bastante
bastante
bien
funciona
este
sistema
.
lo
que
podemos
observar
es
que
los
conceptos
donde
aparecían
este
cómo
se
llama
conceptos
visuales
de
nuestro
pequeño
diccionario
eran
funcionaban
mucho
menos
o
sea
la
precisión
a
veinte
era
mucho
más
baja
que
la
precisión
a
veinte
promedio
en
los
treinta
y
nueve
esos
.
parece
como
si
naturalmente
la
gente
cuando
busca
un
concepto
que
se
clasifica
muy
bien
de
manera
visual
la
gente
no
lo
indexa
.
o
sea
simplemente
eso
no
aparece
en
el
texto
esa
es
la
impresión
es
un
poco
la
impresión
que
da
estos
tipos
de
resultado
.
habría
que
investigar
un
poco
más
ok
y
bueno
y
también
probamos
otro
tipo
de
busca
de
información
basada
en
language
model
y
se
ve
un
poco
lo
mismo
con
una
diferencia
un
poco
más
baja
pero
más
o
menos
el
mismo
el
mismo
comportamiento
general
.
o
sea
que
no
depende
del
modelo
de
búsqueda
de
texto
ok
pero
qué
pasa
exactamente
vamos
lo
lo
que
para
ver
qué
pasa
exactamente
lo
que
hicimos
es
simplemente
comparamos
en
un
axis
vamos
a
comparar
la
precisión
a
veinte
de
los
de
de
una
de
una
de
un
resultado
o
sea
de
un
run
de
una
submisión
simplemente
texto
contra
una
aplicando
el
filtro
.
y
lo
que
vamos
a
ver
es
que
todo
lo
que
no
fue
modificado
por
nuestro
sistema
porque
no
había
concepto
está
en
la
diagonal
.
por
que
es
normal
es
el
mismo
valor
y
vamos
algunos
de
los
de
los
de
lo
de
lo
que
sí
ha
sido
modificado
se
modifica
y
funciona
mucho
mejor
.
por
ejemplo
tenemos
el
topic
cincuenta
y
ocho
que
se
mejoró
mucho
el
topic
cuarenta
y
cuatro
que
se
mejoró
mucho
conclusión
este
tipo
de
método
siempre
mejora
los
resultados
a
la
precisión
de
veinte
.
atención
es
la
precisión
de
veinte
o
sea
nos
interesan
las
primeras
veinte
imágenes
y
no
el
recall
aquí
nosotros
botamos
bastante
imágenes
de
las
primeras
.
y
claro
tenemos
la
impresión
que
funciona
muy
bien
pero
para
en
un
contexto
de
búsqueda
de
información
tipo
Google
o
algo
así
es
un
sistema
que
funciona
bastante
bien
.
ok
entonces
este
conclusión
de
esta
parte
es
textbased
image
retrieval
puede
puede
beneficiar
del
uso
de
concepto
detección
automática
a
pesar
de
los
que
los
detectores
no
son
de
muy
buena
calidad
.
y
para
algunos
de
los
de
los
topics
o
para
alguno
de
los
casos
funciona
muy
bien
.
y
en
los
otros
casos
no
no
no
afecta
ahora
cómo
detectar
eso
ya
es
lo
que
yo
quisiera
que
me
responda
a
mí
la
población
del
del
PNL
.
que
me
responda
a
mí
me
diga
cuál
concepto
cómo
hago
yo
para
extender
mi
query
y
saber
qué
tipo
de
concepto
visual
tengo
que
utilizar
.
porque
funciona
bien
el
problema
está
en
saber
qué
concepto
visual
utilizar
.
ok
bueno
ok
entonces
no
sé
si
.
no
no
pero
ya
porque
cuando
es
muy
largo
y
a
esta
hora
lo
puedo
hacer
un
poco
más
menos
sin
entrar
en
detalles
.
y
y
vamos
a
ver
entonces
bueno
lo
que
acabamos
de
ver
es
lo
que
ustedes
conocen
un
poco
que
es
bueno
vamos
a
utilizar
el
texto
verdad
.
entonces
ustedes
van
a
decir
claro
yo
puedo
resolver
todos
los
problemas
de
mi
vida
sin
ningún
problema
.
yo
puedo
vivir
feliz
porque
claro
yo
con
el
texto
yo
voy
a
Google
yo
me
meto
en
Google
y
resuelvo
el
problema
.
bueno
puede
ser
que
pase
un
poquito
más
de
tiempo
y
tal
entonces
lo
que
lo
que
yo
les
propongo
aquí
es
que
ustedes
me
digan
y
pueden
utilizar
Google
pueden
utilizar
lo
que
ustedes
quieran
que
me
digan
quién
es
el
autor
de
esta
pintura
.
ok
les
doy
una
les
puedo
ayudar
.
les
puedo
dar
el
GPS
position
de
la
imagen
si
quieren
donde
fue
sacada
saben
cuál
es
bueno
les
digo
que
es
en
el
Louvre
la
sacamos
en
el
eso
es
del
Louvre
bueno
justamente
eso
es
lo
que
nosotros
queremos
hacer
eso
es
lo
que
la
idea
aquí
va
a
ser
voltear
el
problema
.
tengo
una
imagen
y
lo
que
yo
quiero
ahora
es
que
me
consigan
el
texto
.
ok
bueno
entonces
cómo
cómo
qué
es
lo
que
proponemos
.
esto
es
un
trabajo
que
hicimos
con
Boris
de
la
EPFL
.
y
la
idea
es
hacer
un
sistema
móvil
para
guiar
a
los
turistas
en
en
en
un
museo
.
esto
es
basado
en
un
teléfono
o
un
móvil
este
y
vamos
a
utilizar
lo
que
vamos
a
hacer
es
que
vamos
a
utilizar
la
cámara
del
móvil
para
detectar
qué
cuadro
es
.
o
sea
por
ejemplo
vamos
a
los
museos
le
damos
y
detectamos
ustedes
me
van
a
decir
sí
bueno
pero
de
qué
me
sirve
a
mí
sacarle
la
foto
al
cuadro
si
yo
tengo
el
nombre
allí
abajo
.
bueno
es
que
yo
les
puse
la
pregunta
fácil
si
les
pregunto
algo
más
entonces
ustedes
me
van
a
decir
bueno
.
si
les
les
les
puse
la
pregunta
no
no
me
acuerdo
qué
iba
a
decir
.
si
yo
les
pregunto
a
ustedes
les
dicen
bueno
yo
les
puse
la
pregunta
yo
les
digo
bueno
díganme
por
ejemplo
qué
es
qué
escuela
es
o
algo
así
.
entonces
me
van
a
decir
bueno
no
importa
yo
me
lo
anoto
y
voy
a
la
casa
y
yo
lo
busco
en
Google
entonces
yo
lo
que
les
voy
a
les
puedo
poner
como
ejemplo
aquí
no
hicimos
el
experimento
pero
es
la
misma
técnica
funciona
perfectamente
ustedes
pueden
apuntar
a
uno
de
los
personajes
del
cuadro
y
basado
en
eso
yo
le
puedo
designar
la
descripción
que
es
lo
mismo
.
a
partir
de
una
imagen
yo
le
buscaré
la
descripción
del
personaje
ya
no
del
cuadro
les
voy
a
decir
este
personaje
tiene
que
ver
esto
y
lo
otro
con
la
imagen
eso
dudo
que
sin
leer
un
artículo
bastante
largo
ustedes
logren
saber
.
bueno
en
fin
eso
es
para
un
poco
justificar
este
tipo
de
sistemas
que
probablemente
ustedes
verán
dentro
de
los
próximos
años
en
los
supermercados
.
la
gente
va
a
tener
de
la
telefónica
usted
va
a
poder
detectar
un
producto
comercial
por
ejemplo
Cocacola
y
va
le
va
a
decir
ok
pero
el
supermercado
de
al
lado
es
más
barato
.
ok
y
bueno
y
como
y
si
no
funciona
no
importa
porque
de
todas
maneras
todo
el
el
móvil
se
vende
muy
bien
.
ok
ahora
qué
pasa
esto
es
bastante
interesante
no
se
necesita
ninguna
instalación
no
lo
tiene
que
instalar
el
museo
se
puede
instalar
simplemente
desde
el
móvil
y
pero
hay
un
problema
cuál
es
el
problema
que
podemos
conseguir
imágenes
que
se
parecen
mucho
pero
aquí
las
imágenes
no
se
van
a
parecer
mucho
.
por
qué
porque
vamos
a
tener
problemas
de
reflexiones
porque
ponen
vidrios
los
los
del
museo
no
sé
pero
ponen
vidrios
delante
de
los
de
los
cuadros
.
hay
deformación
si
yo
saco
la
foto
de
un
lado
se
me
va
a
deformar
la
imagen
y
hay
gente
que
tiene
la
mala
maña
no
sé
si
se
han
fijado
en
los
museos
de
pasar
cuando
uno
quiere
sacar
la
foto
pasan
delante
.
entonces
el
sistema
de
búsqueda
tiene
que
ser
bastante
robusto
a
este
tipo
de
problemas
.
por
eso
es
que
nosotros
utilizamos
claro
aquí
no
les
voy
a
presentar
cómo
funciona
esto
en
detalle
pero
como
ven
es
una
técnica
que
está
así
como
en
en
en
el
aire
actual
.
y
mucha
gente
la
está
utilizando
hay
otros
tipos
de
método
por
ejemplo
que
es
lo
mismo
un
poco
más
acelerado
.
en
tal
nosotros
hicimos
un
estudio
sobre
este
tema
y
después
hicimos
un
sistema
perdón
.
después
hicimos
un
sistema
de
búsqueda
acelerado
basado
en
.
es
un
poco
misma
la
idea
es
poder
acelerar
la
búsqueda
de
la
imagen
dentro
de
buscar
un
poco
rápidamente
la
la
la
imagen
el
correcto
match
pero
de
manera
rápida
ok
.
no
sé
no
no
entremos
mucho
en
detalles
ok
qué
pasa
con
los
teléfonos
celulares
perdón
móviles
los
teléfonos
móviles
lo
que
pasa
es
que
a
ustedes
se
los
venden
por
seiscientos
euros
o
cuatrocientos
euros
si
no
se
ponen
un
plan
de
cuatro
años
.
esos
teléfonos
tienen
un
procesador
que
es
de
lo
más
barato
que
existe
en
el
mercado
.
y
calculan
muy
lentamente
por
lo
tanto
nosotros
hicimos
primero
test
empezamos
a
hacer
algunos
tests
sobre
la
la
busca
de
información
móvil
.
y
descubrimos
bastante
rápidamente
que
si
uno
quiere
hacer
los
cálculos
en
el
móvil
el
señor
tiene
que
sacar
la
foto
irse
a
tomar
un
café
y
regresar
en
la
tarde
para
saber
qué
cuadro
era
.
entonces
hicimos
una
arquitectura
que
simplemente
el
móvil
es
un
aparato
que
permite
transferir
la
pregunta
a
un
servidor
que
hace
el
que
hace
todos
los
cálculos
y
es
bastante
mucho
es
mucho
más
rápido
.
ahora
hay
que
mandar
toda
la
imagen
entonces
lo
que
nosotros
vamos
a
hacer
es
que
vamos
a
tratar
de
fijarnos
en
diferente
tipo
de
resoluciones
.
por
qué
porque
primero
hay
que
mandar
una
imagen
no
puede
ser
muy
grande
primero
y
segundo
que
para
calcular
las
features
de
la
imagen
tenemos
que
hacerlo
de
bastante
manera
rápida
.
mientras
más
grande
la
imagen
más
tardamos
para
calcular
las
features
y
en
el
caso
de
la
esto
es
exponencial
ok
bueno
para
darle
un
poco
la
idea
de
si
funciona
o
no
funciona
tenemos
una
base
de
referencia
utilizamos
una
base
de
referencia
que
nos
prestaron
los
los
amigos
del
húngaros
de
la
web
galery
of
art
que
es
excelente
se
la
recomiendo
si
quieren
buscar
alguna
cosa
.
ellos
tienen
a
dos
mil
doscientos
artistas
registrados
.
hay
dieciséis
mil
ochocientas
piezas
de
arte
y
para
no
poner
el
problema
muy
difícil
este
elegimos
solamente
las
mil
doscientas
imágenes
de
los
cuadros
del
Louvre
admitiendo
que
o
sea
como
hipótesis
de
trabajo
que
le
podemos
pedir
al
utilizador
cuando
llegue
decir
en
qué
museo
está
.
entonces
ya
podemos
simplificar
un
poco
el
problema
ok
un
escenario
bastante
realista
o
simplemente
conseguimos
la
en
qué
posición
se
encuentra
.
y
sabemos
que
está
en
el
Louvre
en
fin
después
para
los
tests
elegimos
cuarenta
pinturas
y
cuatro
perspectivas
diferentes
.
y
varios
tipos
de
resoluciones
para
que
uno
vea
el
problema
de
la
resolución
para
poderle
darle
un
poco
el
sentimiento
a
la
resolución
a
mano
de
izquierda
tenemos
la
imagen
la
imagen
que
vimos
al
principio
a
una
resolución
de
sesenta
y
cuatro
por
cincuenta
y
uno
.
si
ya
era
difícil
reconocer
la
imagen
de
buena
calidad
imagínense
de
más
baja
calidad
.
y
bueno
esto
es
una
imagen
de
doscientos
cincuenta
y
seis
hicimos
experimentos
hasta
quinientos
doce
por
el
proporcional
no
.
este
sobre
el
tema
de
la
perspectiva
aquí
tenemos
una
imagen
arriba
y
a
la
izquierda
tenemos
una
imagen
frontal
.
y
después
tenemos
una
imagen
a
la
derecha
a
la
arriba
a
la
derecha
una
perspectiva
de
la
derecha
.
fíjense
que
elegimos
cuadros
de
diferentes
tamaños
fíjense
que
los
cuadros
están
tienen
tienen
tienen
marcos
.
fíjense
que
hay
gente
que
se
nos
atraviesa
por
ejemplo
cuando
se
hace
una
imagen
a
distancia
.
en
fin
tratamos
de
hacer
una
base
de
una
base
de
tests
bastante
realista
.
ok
qué
observamos
bueno
observamos
que
claro
lo
que
se
esperaba
un
poco
era
que
si
aumentábamos
la
resolución
de
la
imagen
lo
que
iba
a
pasar
es
que
se
mejoraba
mucho
el
el
tiempo
de
cálculo
iba
a
aumentar
mucho
.
aquí
comparamos
básicamente
tres
técnicas
o
sea
en
este
gráfico
simplemente
vemos
tres
técnicas
la
la
que
es
una
speed
up
y
la
fast
que
es
lo
que
nosotros
proponemos
.
y
como
imagino
que
nadie
se
sorprende
nuestro
método
combinado
es
el
más
rápido
y
probablemente
el
más
eficaz
.
ok
pero
lo
que
quiero
decir
que
es
aumentamos
un
poco
s
y
fíjense
el
aumenta
.
esto
es
una
escala
en
segundos
y
nos
conseguimos
en
algo
tipo
mil
quinientos
segundos
.
que
es
bastante
bastante
alto
no
entonces
por
eso
fue
que
nosotros
propusimos
después
la
aceleración
.
ok
ahora
la
performance
algún
truco
tiene
que
haber
cómo
hacemos
nosotros
para
acelerar
al
acelerar
lo
que
hicimos
es
un
sistema
de
indexación
de
la
base
de
datos
que
nos
permite
adivinar
básicamente
.
adivinar
cuál
es
la
imagen
pero
claro
de
vez
en
cuando
nos
tenemos
que
equivocar
o
sea
no
podemos
ir
igual
de
rápido
que
los
demás
o
sea
no
podemos
ir
cien
veces
más
rápido
que
los
demás
pero
eso
sí
no
equivocarse
nunca
.
o
sea
puede
ser
que
se
pueda
pero
lo
que
nosotros
hicimos
es
una
receta
heurística
no
.
y
aquí
vemos
que
si
utilizamos
doscientos
cincuenta
y
seis
lo
que
era
lo
más
lento
hace
un
hace
un
momento
no
nos
equivocamos
absolutamente
nunca
tenemos
el
cien
por
ciento
o
sea
esto
es
el
rango
de
la
imagen
en
qué
en
qué
rango
ahí
aparece
.
y
si
agarramos
el
rango
uno
la
tenemos
cien
por
cien
entonces
agarramos
en
los
dos
primeros
rangos
cuántas
veces
aparece
y
bueno
y
aquí
vemos
que
por
ejemplo
ciento
veintiocho
es
bastante
eficaz
ahora
hay
efectos
bastante
interesantes
que
no
puedo
explicar
aquí
.
que
no
voy
a
explicar
pero
por
ejemplo
algo
de
mejor
calidad
acelerado
funciona
doscientos
cincuenta
y
seis
fast
contra
ciento
veintiocho
fast
la
funciona
no
funciona
tan
bien
.
por
qué
porque
el
momento
habría
que
ver
cómo
funciona
el
algoritmo
de
aceleración
hace
que
simplemente
hacemos
muchos
errores
en
el
momento
de
acelerar
ok
.
en
fin
ese
es
es
eso
bueno
entonces
este
para
para
mostrarle
un
poco
cómo
funciona
el
sistema
no
no
se
pudo
.
ok
.
este
para
mostrarles
el
el
sistema
entonces
bueno
esto
es
hecho
en
un
la
oficina
entonces
no
tenemos
el
tenemos
pero
tenemos
un
cuadro
de
de
alta
calidad
.
y
entonces
esto
fue
programado
en
o
sea
tenemos
versión
varias
versiones
porque
el
estudiante
estaba
fascinado
por
la
programación
entonces
la
tenemos
en
Android
.
o
sea
si
se
compran
un
GPhone
lo
pueden
se
lo
pueden
instalar
sin
ningún
problema
lo
tenemos
en
la
HP
en
el
Windows
Mobile
HP
.
en
fin
el
el
el
el
estudiante
le
gustaba
programar
.
entonces
la
interface
no
es
ideal
porque
es
un
prototipo
.
lo
que
nos
interesaba
es
saber
la
la
la
la
calidad
de
la
programación
entonces
se
toma
la
imagen
ok
y
después
fíjense
que
la
imagen
era
blanco
y
negro
no
por
qué
porque
no
importa
o
sea
este
sistema
es
bastante
robusto
y
no
importa
porque
el
descriptor
se
fija
que
no
se
los
expliqué
se
no
toma
en
cuenta
los
colores
.
o
sea
cuando
esta
mañana
oímos
que
Paul
dijo
que
ese
es
el
mejor
sistema
sí
es
verdad
es
lo
que
se
más
se
ha
utilizado
hasta
el
día
de
hoy
.
se
ha
utilizado
pero
los
no
utilizan
el
color
aunque
existen
claro
versiones
color
del
.
no
sé
cuánto
se
puede
ganar
y
bueno
y
al
final
descubrimos
que
efectivamente
descubrimos
que
era
el
fortune
teller
la
versión
de
París
.
sí
creo
que
hay
una
solo
versión
es
del
el
del
as
el
as
de
pique
y
y
el
as
de
trèfle
en
uno
en
Nueva
York
y
uno
en
París
.
en
fin
conseguimos
el
no
es
el
yo
creo
que
sí
en
fin
ok
entonces
así
es
que
funciona
el
sistema
.
y
con
esto
quería
terminar
.
quería
decirles
que
yo
pienso
que
la
anotación
automática
es
este
este
esta
idea
de
traducción
es
posible
especialmente
para
algunos
conceptos
.
hay
conceptos
que
aunque
interesen
mucho
al
ejército
americano
son
bastante
difíciles
de
detectar
.
este
tenemos
un
yo
creo
que
estos
resultados
de
estos
conceptos
se
pueden
utilizar
para
mejorar
la
busca
de
información
texto
típica
.
y
este
hay
una
un
una
una
un
unos
pocos
trabajos
que
están
empezando
a
ver
la
relación
entre
los
diferentes
conceptos
en
el
momento
del
aprendizaje
de
los
conceptos
.
o
sea
porque
si
yo
aprendo
y
yo
veo
que
tengo
agua
bueno
y
tengo
un
objeto
que
puede
ser
que
sea
un
barco
entonces
bueno
puedo
adivinar
que
es
un
barco
.
entonces
tratar
de
utilizar
este
hecho
que
tenemos
la
relación
nosotros
tenemos
algunos
trabajos
también
sobre
eso
no
ok
yo
creo
que
esto
puede
mejorar
la
búsqueda
de
información
texto
classic
.
y
claro
y
eso
ya
funciona
hoy
en
día
con
conceptos
bastante
simples
para
que
que
podemos
tipo
color
y
caras
y
bueno
.
ustedes
lo
pueden
ver
en
en
internet
no
hay
ejemplos
hay
compañías
que
funcionan
con
eso
ok
yo
creo
que
este
yo
espero
que
los
convencí
.
si
ustedes
son
la
gente
que
trabaja
en
texto
espero
que
los
convencí
que
texto
no
es
lo
único
.
o
sea
no
es
la
única
solución
que
existe
bueno
claro
si
hay
texto
yo
soy
el
primero
que
utilizaría
texto
.
pero
si
no
hay
habrá
que
ver
cómo
hacer
para
mejorar
los
resultados
.
y
yo
pienso
que
el
la
investigación
sobre
el
tema
de
la
busca
de
información
texto
no
en
la
parte
de
procesamiento
del
lenguaje
natural
pero
sino
en
la
búsqueda
texto
clásica
con
keywords
.
yo
creo
que
ha
llegado
un
ya
se
consiguen
resultados
básicamente
las
diferencias
son
pequeñas
entre
los
diferentes
sistemas
.
y
pienso
que
hay
que
empezar
a
ver
cosas
alrededor
yo
pienso
que
hay
ver
cosas
alrededor
el
contexto
un
poco
cómo
se
hace
la
personalización
el
utilizador
y
tal
y
hay
que
ver
un
poco
alrededor
de
la
misma
manera
que
yo
trato
de
ver
las
imágenes
y
la
media
también
se
puede
ver
el
utilizador
y
las
cosas
que
están
alrededor
.
ok
entonces
yo
con
esto
quería
terminar
y
para
los
que
querían
saber
de
qué
cuadro
se
se
qué
cuadro
era
el
cuadro
era
de
Correggio
.
mil
cuatrocientos
noventa
es
el
Mystic
Marriage
of
Saint
Catherine
está
en
el
Louvre
claro
los
experimentos
los
hicimos
en
el
Louvre
eso
sí
lo
hubiesen
podido
adivinar
y
pertenece
a
un
grupo
de
la
Madonna
Painting
donde
Correggio
participaba
donde
representaba
el
ideal
femenino
.
gracias
por
su
atención
