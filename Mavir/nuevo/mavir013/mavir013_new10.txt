bueno
muchas
gracias
a
la
organización
por
invitarme
.
y
en
particular
por
haberlo
hecho
en
el
en
el
día
de
las
empresas
.
para
mí
es
una
sorpresa
porque
bueno
soy
soy
de
la
academia
no
cien
por
cien
.
está
bien
eso
quiere
decir
que
a
lo
mejor
hemos
conseguido
hacer
algo
útil
.
o
también
puede
querer
decir
que
que
lo
que
hacemos
ya
no
tiene
ningún
valor
científico
.
me
voy
a
quedar
con
la
primera
opción
no
.
eh
bien
como
se
trata
de
un
de
unas
jornadas
multimedia
pues
en
el
título
me
voy
a
centrar
en
los
dibujitos
.
este
es
el
logo
del
del
CLEF
que
como
comentaba
Felisa
es
una
inciativa
en
la
que
participan
más
de
cien
grupos
de
investigación
todos
los
años
y
que
se
dedica
a
hacer
evaluaciones
sistemáticas
y
comparativas
entre
sistemas
de
acceso
a
información
multilingüe
en
general
.
y
dentro
de
del
CLEF
pues
hay
muchas
tareas
un
poco
es
tipo
olimpiadas
hay
muchas
pruebas
distintas
para
distintos
tipos
de
sistemas
.
y
dentro
de
esa
enorme
base
de
investigadores
hay
una
pequeña
aldea
que
es
la
de
los
investigadores
que
nos
dedicamos
sobre
todo
a
estudiar
los
problemas
de
acceso
a
la
información
desde
un
punto
de
vista
interactivo
o
sea
teniendo
en
cuenta
la
perspectiva
del
usuario
.
y
este
es
nuestro
logo
como
podéis
ver
.
de
nuevo
es
es
es
el
CLEF
es
el
logo
de
CLEF
pero
donde
teníamos
aquí
una
llavecita
maravillosamente
dibujada
que
te
daba
acceso
al
conocimiento
del
mundo
entero
que
está
aquí
pues
aquí
lo
que
tenemos
es
que
de
repente
la
ce
se
ha
convertido
en
los
brazos
de
un
usuario
con
unas
manos
así
gordas
y
torponas
que
deforma
completamente
todo
el
todo
el
logotipo
.
y
esto
la
verdad
es
que
si
hubiera
que
resumir
la
charla
en
una
transparencia
probablemente
esta
sería
la
mejor
no
.
cuando
está
el
usuario
de
por
medio
la
cosa
se
complica
bastante
.
bien
la
mi
segunda
transparencia
la
he
añadido
esta
noche
después
de
escuchar
las
charlas
de
ayer
.
ayer
Marcin
por
la
tarde
en
su
charla
que
fue
estupenda
por
cierto
empezaba
diciendo
que
la
búsqueda
de
imágenes
por
palabras
clave
funcionaba
muy
bien
.
y
ponía
un
ejemplo
de
Google
en
el
que
ponía
su
apellido
y
salían
cosas
relacionadas
con
su
madre
y
con
su
padre
.
bueno
pues
como
hoy
es
la
jornada
de
empresas
empezaré
usando
el
mismo
tipo
de
transparencia
para
decir
que
la
búsqueda
de
imágenes
por
palabras
clave
no
funciona
en
absoluto
.
esto
es
un
ejemplo
de
una
charla
que
di
hace
unos
meses
en
en
Atos
en
la
que
yo
quería
un
dibujito
de
un
alquimista
con
la
piedra
filosofal
para
ilustrar
mi
charla
.
así
que
empecé
buscando
alchemist
que
no
parece
mala
idea
.
y
estos
son
los
resultados
.
son
sobre
todo
sobre
Fullmetal
Alchemist
que
es
una
serie
de
dibujos
animados
no
lo
sé
exactamente
.
esto
de
los
buscadores
es
un
poco
como
los
los
camareros
no
.
si
les
pides
una
coca
cola
fabuloso
te
la
traen
inmediatamente
.
y
si
le
pides
una
pepsi
twist
pues
te
trae
una
coca
cola
también
no
.
esto
es
un
poco
lo
que
pasa
aquí
.
la
mayoría
de
la
gente
estará
buscando
por
Fullmetal
Alchemist
me
imagino
.
así
que
a
mí
me
toca
fastidiarme
.
esto
por
cierto
también
probé
buscando
por
la
piedra
filosofal
que
era
la
otra
alternativa
.
y
bueno
pues
me
salío
ahí
alguna
actriz
y
eso
pero
sobre
todo
cosas
de
Harry
Potter
.
no
no
conseguí
mi
objetivo
en
absoluto
.
esto
pasa
porque
en
el
fondo
la
búsqueda
por
palabras
clave
es
muchísimo
más
complicada
que
lo
que
hace
un
buscador
web
.
porque
un
buscador
web
busca
por
palabras
clave
pero
tiene
toda
la
información
del
contexto
de
los
hipervínculos
de
la
web
para
saber
cuáles
son
las
cosas
más
relevantes
.
quería
poneros
este
una
pequeña
consulta
.
bueno
no
somos
muchos
pero
por
favor
levantad
la
mano
.
esto
son
dos
posibles
.
bueno
son
dos
dos
fotografías
de
la
flor
del
azafrán
.
quién
prefiere
la
fotografía
de
la
izquierda
.
quién
prefiere
esta
.
y
quién
prefiere
la
de
la
derecha
.
bueno
no
está
mal
estamos
bastante
equilibrados
.
creo
que
gana
la
de
la
izquierda
pero
claro
depende
también
de
lo
que
vaya
a
hacer
uno
con
ella
no
.
bueno
yo
lo
que
quería
decir
aquí
.
me
habéis
fastidiado
el
ejemplo
la
verdad
pero
.
a
mí
me
gusta
más
la
de
la
izquierda
.
lo
a
lo
que
iba
yo
aquí
es
que
bueno
una
cosa
es
la
relevancia
no
.
en
el
caso
anterior
yo
no
conseguía
encontrar
un
una
un
alquimista
con
su
piedra
filosofal
.
en
este
caso
la
cosa
es
un
poco
más
allá
.
hay
muchísimas
imágenes
de
azafrán
.
éstas
imágenes
están
tomadas
de
Flickr
.
yo
sé
cuáles
son
los
permisos
que
tiene
cada
una
respecto
a
cómo
se
puede
usar
.
así
yo
podría
utilizar
Flickr
perfectamente
para
ilustrar
mi
actículo
sobre
el
azafrán
pongamos
no
porque
sé
cuál
es
puedo
perfectamente
poner
en
mi
artículo
.
pero
si
me
pongo
a
buscar
fotos
claro
yo
lo
que
quiero
son
las
fotos
más
chulas
.
y
cómo
demonios
puede
un
sistema
de
recuperación
de
imágenes
decidir
cuáles
son
las
fotos
más
chulas
.
es
francamente
complicado
.
o
no
.
o
no
porque
en
Flickr
efectivamente
es
una
red
social
y
hay
mucha
información
que
tiene
Flickr
sobre
lo
que
hacen
en
ella
los
usuarios
lo
que
les
gusta
y
lo
que
no
.
y
de
hecho
esta
foto
está
anotada
como
favorita
no
sé
si
era
setenta
o
noventa
veces
.
y
esta
anotada
cinco
veces
.
o
sea
que
digamos
que
cuando
Flickr
.
de
hecho
cuando
Flickr
hace
un
ranking
lo
hace
utilizando
esa
información
de
favoritos
.
o
sea
que
es
una
información
completamente
manual
pero
es
una
información
que
está
en
el
sistema
.
parecido
a
lo
que
hace
Google
cuando
utiliza
la
información
de
hipervínculos
que
han
sido
creados
manualmente
pero
que
sirven
para
hacer
un
ranking
de
resultados
también
.
sólo
hay
un
pequeño
problema
.
y
es
que
estas
dos
fotos
nunca
aparecen
juntas
en
los
resultados
de
Flickr
.
en
este
caso
porque
están
anotadas
en
idiomas
distintos
.
y
es
una
pena
.
cuando
uno
está
buscando
imágenes
realmente
el
hecho
de
que
los
documentos
estén
en
chino
o
en
japonés
en
italiano
le
da
igual
e
inmediatamente
va
a
saber
cuál
es
la
que
le
gusta
no
.
es
diferente
si
estás
con
textos
que
a
lo
mejor
un
texto
en
chino
pues
te
va
a
ser
más
difícil
usarlo
.
pero
con
imágenes
el
cruzar
la
barrera
del
del
idioma
es
algo
que
es
claramente
beneficioso
.
y
con
esto
más
o
menos
yo
creo
que
hemos
cuberto
todas
las
las
etiquetas
que
le
había
puesto
al
al
título
de
la
charla
que
de
hecho
con
el
título
de
la
charla
fue
complicado
.
porque
sí
bueno
queríamos
llamarla
buscando
cangrejos
en
Flickr
.
estábamos
Víctor
y
yo
ahí
pensando
en
ponerle
un
título
chulo
.
pero
claro
esto
no
tenía
ningún
contenido
ninguna
información
.
ahora
si
.
de
lo
que
yo
quería
hablar
era
de
búsqueda
de
imágenes
.
quería
hablar
de
los
aspectos
multilingües
de
la
búsqueda
de
imágenes
como
os
acabo
de
comentar
.
hacerlo
además
desde
una
perspectiva
interactiva
.
y
además
en
el
entorno
de
la
web
social
o
de
la
web
dos
punto
cero
que
es
el
entorno
de
de
Flickr
como
os
decía
.
era
imposible
hacer
un
título
con
todos
estos
términos
clave
sin
que
fuera
infumable
.
así
que
bueno
por
qué
no
hacerlo
en
modo
web
social
no
así
con
pone
uno
el
título
que
le
da
la
gana
y
luego
ya
en
las
etiquetas
se
habla
del
contenido
y
se
permite
que
se
encuentre
la
información
por
ese
tipo
de
contenido
.
así
que
esta
es
la
segunda
versión
del
título
de
la
charla
la
versión
tal
y
como
estaba
digamos
originalmente
diseñada
.
y
este
es
el
cangrejo
que
lo
volveremos
a
ver
enseguida
.
bien
cómo
es
esto
de
la
perespectiva
del
usuario
.
esto
quizás
desde
la
perspectiva
de
las
empresas
pues
no
hace
falta
explicároslo
pero
para
un
científico
es
algo
realmente
extraño
tener
que
ponerse
en
contacto
con
con
los
seres
humanos
.
la
perspectiva
de
los
investigadores
en
recumeración
de
información
en
general
es
ésta
no
.
el
usuario
necesita
información
la
maquina
le
busca
la
información
y
el
usuario
es
feliz
o
no
.
de
hecho
a
veces
se
mide
binariamente
no
.
sí
no
sí
no
sí
no
y
punto
.
y
hay
que
conseguir
que
la
máquina
lo
haga
lo
mejor
posible
.
por
eso
he
elegido
este
dibujo
de
de
de
Bender
porque
es
es
muy
apropiado
no
.
es
una
máquina
extremadamente
inteligente
pero
bebe
mucho
.
entonces
tiene
un
comportamiento
errático
no
.
puede
parecer
muy
inteligente
o
absolutamente
estúpida
porque
está
borracha
.
en
realidad
claro
todos
sabemos
incluidos
los
informáticos
cuando
usamos
los
sistemas
que
esto
es
una
imagen
completamente
incompleta
y
absurda
.
en
realidad
encontrar
información
es
cosa
de
dos
.
sí
tenemos
la
máquina
que
es
rápida
y
tonta
pero
luego
tenemos
al
otro
lado
al
humano
que
es
muy
listo
y
muy
lento
.
hay
que
aprovechar
la
velocidad
de
la
máquina
y
la
inteligencia
del
del
humano
no
.
hay
un
gran
potencial
para
colaborar
digamos
.
y
de
hecho
a
no
ser
que
uno
esté
navegando
haciendo
una
consulta
navegacional
en
la
que
quiera
encontrar
pues
la
página
del
CSIC
que
efectivamente
es
relativamente
instantáneo
muchas
veces
uno
se
ve
envuelto
en
un
proceso
iterativo
en
el
que
está
ayudándose
de
la
máquina
para
encontrar
la
información
pero
no
es
para
nada
un
prococeso
automático
sino
que
es
un
proceso
de
interacción
.
así
que
si
queremos
saber
qué
sistemas
y
qué
algoritmos
son
los
mejores
para
encontrar
información
no
hay
más
remedio
que
poner
el
usuario
en
el
proceso
de
evaluación
para
saber
cuál
es
la
mejor
manera
de
que
el
usuario
encuentre
la
información
que
al
fin
y
al
cabo
el
usuario
es
el
que
la
necesita
.
la
que
la
la
el
dibujo
es
perfecto
porque
ahí
tenemos
a
Homer
Simpson
que
es
listo
a
veces
.
desde
luego
es
lento
.
y
lo
que
es
más
curioso
a
menudo
no
sabe
lo
que
busca
no
.
éste
sería
el
el
usuario
tipo
.
y
de
hecho
es
una
situación
frecuentísima
.
uno
está
buscando
pero
es
algo
exploratorio
.
y
de
hecho
las
cosas
que
encuentra
le
despiertan
o
le
aclaran
qué
es
lo
que
realmente
necesita
o
le
llevan
a
caminos
completamente
inexplorados
.
así
que
en
fin
la
la
imagen
es
mucho
más
compleja
que
la
que
en
general
casi
todos
los
investigadores
nos
planteamos
.
así
que
llega
un
momento
en
el
que
uno
en
particular
en
mi
caso
siente
la
necesidad
de
hacer
algo
útil
.
y
en
ese
momento
está
perdido
porque
empieza
a
trabajar
con
usuarios
y
ya
nunca
más
se
recupera
.
ahora
lo
veremos
un
poco
.
el
CLEF
tiene
su
contrapartida
en
Estados
Unidos
en
el
TREC
que
es
otra
campaña
de
evaluación
internacional
de
sistemas
de
acceso
de
sistemas
de
acceso
a
información
en
general
.
esa
frase
de
arriba
users
screw
things
up
es
una
cita
literal
no
diré
de
quién
de
uno
de
los
organizadores
del
TREC
.
que
básicamente
quiere
decir
que
una
vez
que
metes
usuarios
estás
completamente
perdido
.
un
problema
que
tienen
realmente
gordo
que
hemos
comprobado
en
nuestro
laboratorio
es
que
no
se
les
puede
resetear
.
no
se
les
puede
lobotomizar
.
es
es
es
un
desastre
.
o
sea
se
les
tiene
que
alimentar
.
es
gente
que
por
ejemplo
dependiendo
de
cómo
haya
dormido
te
hace
las
cosas
de
una
manera
o
de
otra
de
si
ha
tenido
bronca
con
algún
familiar
la
noche
anterior
.
si
tienen
hambre
también
hacen
las
cosas
más
precipitadamente
etcétera
.
es
un
auténtico
desastre
.
sobre
todo
con
resetear
me
refiero
a
un
problema
gravísimo
y
es
que
cuando
un
investigador
compara
dos
sistemas
de
recuperación
de
información
normalmente
porque
quiere
comprobar
que
su
algoritmo
produce
una
mejora
entonces
coge
un
sistema
de
referencia
y
luego
un
sistema
que
incorpora
su
algoritmo
.
simplemente
les
da
a
los
mismos
las
mismas
tareas
.
cada
uno
las
resuelve
y
luego
mira
a
ver
cuál
las
resuerve
mejor
.
esto
en
cuanto
tienes
un
usuario
ya
no
lo
puedes
hacer
porque
si
le
pones
al
usuario
con
el
sistema
A
a
resolver
esta
tarea
cuando
le
pones
con
el
sistema
B
el
tío
se
acuerda
de
lo
que
ha
hecho
antes
.
y
por
lo
tanto
su
forma
de
buscar
es
completamente
distinta
.
y
a
eso
me
refiero
con
lo
de
que
no
se
les
puede
resetear
.
y
ese
es
un
problema
enorme
.
cuando
se
plantea
metodológicamente
cómo
evaluar
con
usuarios
.
además
en
TREC
la
gente
que
trabajaba
en
aspectos
interactivos
les
les
gustaba
mucho
mostrar
a
los
desarrolladores
de
sistemas
sistemas
ad
hoc
que
las
diferencias
entre
los
sistemas
desaparecían
en
cuanto
ponían
usuarios
.
cogían
sistemas
completamente
contrapuestos
como
un
sistema
booleano
que
es
lo
más
básico
que
se
puede
tener
y
luego
el
sistema
más
avanzado
del
mercado
en
ese
momento
que
había
ganado
todas
las
competiciones
ponían
unos
cuantos
usuarios
a
buscar
información
y
la
conclusión
era
que
no
había
ninguna
diferencia
entre
los
dos
sistemas
.
era
un
mensaje
muy
deprimente
para
la
gente
que
hacía
sistemas
.
y
y
eso
les
gustaba
mucho
a
los
que
trabajaban
en
cosas
orientadas
a
usuarios
.
ahora
bien
entonces
ellos
decían
lo
que
hay
que
hacer
es
mejores
interfaces
.
hay
que
asistir
al
usuario
mejor
.
cuanto
mejor
asistas
al
usuario
mejor
encontrará
la
información
.
no
tanto
depende
de
que
haya
un
treinta
por
ciento
de
variación
en
el
ranking
sino
de
cómo
le
ayudo
yo
a
encontrar
información
.
bueno
pues
bien
resulta
que
encontraban
que
las
diferencias
entre
sistemas
interactivos
tampoco
resultaban
en
una
mejora
de
de
la
búsqueda
.
conclusión
era
realmente
un
.
creo
que
los
organizadores
se
querían
cargar
la
tarea
.
lo
que
pasa
es
que
los
que
trabajaban
en
eso
eran
muy
muy
entusiastas
.
otra
cosa
que
se
descubrió
en
esa
tarea
interactiva
es
que
los
sistemas
de
de
búsqueda
de
respuesta
de
question
answering
eran
completamente
inútiles
desde
la
perspectiva
del
usuario
.
hicieron
una
experimentación
en
la
que
muchos
grupos
de
investigación
sentaban
a
un
montón
de
gente
y
les
ponían
a
buscar
la
información
que
solemos
buscar
en
la
web
.
pues
el
típico
tipo
de
preguntas
de
bueno
quiero
viajar
a
tal
sitio
y
quiero
saber
qué
es
lo
que
tengo
que
ver
o
cuáles
pueden
ser
unos
hoteles
razonables
etcétera
.
y
les
ponían
a
buscar
.
y
en
un
momento
dado
en
la
lista
de
distribución
de
discusión
pues
había
uno
que
decía
tengo
un
problema
es
que
se
ponen
a
ponen
la
consulta
en
Google
y
los
tres
primeros
hits
ya
tienen
la
respuesta
ahí
y
la
ven
dentro
del
snippet
que
devuelve
Google
lo
resuelven
y
ya
está
.
se
me
acaba
el
experimento
enseguida
.
entonces
para
qué
necesitas
un
sistema
de
question
answering
que
es
tan
complejo
cuando
en
realidad
lo
mejor
es
tener
recuperación
de
información
rápida
y
tonta
y
un
tío
lento
pero
listo
que
vea
el
snippet
y
rápidamente
detecte
dónde
está
la
respuesta
.
bueno
dan
ganas
de
cerrar
la
charla
y
irse
a
casa
no
.
bueno
pues
no
.
no
por
una
razón
.
una
de
nuestras
hipótesis
es
que
cuando
estás
en
un
entorno
multilingüe
la
cosa
cambia
radicalmente
.
fijaos
.
vais
a
decir
no
hombre
qué
tontería
.
se
hace
traducción
automática
y
ya
está
no
.
es
lo
mismo
.
básicamente
es
lo
mismo
.
coges
traduces
los
documentos
y
fuera
.
pues
no
es
tan
fácil
.
fijaos
por
ejemplo
esto
es
una
página
es
un
producto
en
eBay
.
seguramente
es
traducción
automática
porque
por
ejemplo
a
ver
quién
puede
decirme
qué
significa
amigacho
y
ntcs
ntsc
.
a
mí
me
ha
costado
un
rato
.
si
si
conocemos
los
dos
idiomas
al
cabo
de
un
rato
y
gracias
a
la
pista
de
ntsc
.
creo
que
Isidro
ya
lo
tiene
no
.
efectivamente
amigacho
es
pal
.
eso
no
es
nada
mirad
esto
.
el
jugador
especial
de
youtube
construyó
a
la
derecha
que
probablemente
es
el
el
el
el
player
no
el
reproductor
de
música
no
el
jugador
sino
el
player
.
y
está
built
inside
probablemente
no
del
del
navegador
.
y
etcétera
etcétera
.
el
tacto
del
ipod
es
el
único
ipod
que
le
da
el
acceso
sin
hilos
a
la
tela
.
vosotros
os
reís
porque
sabéis
algo
de
inglés
y
porque
además
estáis
en
el
mundillo
pero
si
no
estaríais
completamente
desconcertados
.
imaginaos
que
un
usuario
está
buscando
información
y
está
viendo
este
tipo
de
documentos
.
primero
un
problema
es
cómo
reconoce
que
un
documento
es
relevante
que
es
un
proceso
es
una
parte
fundamental
del
proceso
.
el
sistema
me
da
documentos
y
yo
digo
al
quinto
es
el
que
me
interesa
.
perfecto
.
con
este
tipo
de
cosas
es
bastante
más
bastante
más
complejo
.
ahora
suponiendo
que
encuentras
un
documento
que
te
pueda
interesar
cómo
haces
relevance
feedback
o
sea
cómo
refinas
con
el
sistema
dándole
términos
de
un
documento
.
fijaos
que
son
términos
en
tu
idioma
.
si
los
alimentas
al
sistema
y
el
sistema
lo
vuelve
a
traducir
puede
pasar
cualquier
cosa
.
o
sea
el
proceso
de
refinamiento
en
cuanto
estás
en
un
entorno
multilingüe
es
un
es
un
caos
.
en
conclusión
el
problema
está
en
que
un
usuario
se
adapta
al
modus
operandi
de
un
sistema
en
modo
monolingüe
.
si
tiene
que
hacer
consultas
booleanas
y
a
todos
nos
ha
pasado
.
todavía
si
te
vas
a
un
sistema
bibliotecario
normalmente
el
modo
de
consulta
es
booleano
.
qué
pasa
.
que
sustituyes
la
inteligencia
del
sistema
de
ranking
por
la
tuya
y
haces
una
consulta
booleana
justo
con
los
términos
que
a
ti
te
descartan
la
información
irrelevante
y
te
dan
la
relevante
.
pero
cuando
estás
en
un
modo
multilingüe
y
esta
es
una
hipótesis
fundamental
para
seguir
trabajando
en
este
área
no
puedes
hacer
eso
porque
cruzar
la
barrera
del
idioma
no
es
tan
sencillo
como
a
.
o
sea
no
.
te
puedes
adaptar
a
un
sistema
más
tonto
pero
no
te
puedes
adaptar
a
un
idioma
nuevo
.
ahí
estás
perdido
sin
aistencia
.
no
sé
si
os
he
convencido
de
que
merece
la
pena
investigar
en
esto
.
en
cualquier
caso
voy
a
seguir
hasta
que
me
echen
.
bien
esta
es
un
poco
la
situación
respecto
a
la
investigación
para
que
os
hagáis
una
idea
en
recuperación
de
información
multilingüe
.
es
un
poco
la
cuenta
de
la
vieja
buscando
Google
Scholar
por
este
estos
acrónimos
cross
language
information
retrieval
que
es
el
más
utilizado
y
añadiéndole
user
study
que
es
lo
más
utilizado
cuando
está
en
la
perspectiva
interactiva
.
veis
la
diferencia
de
publicaciones
.
esto
son
volumen
de
publicaciones
en
la
base
de
datos
de
Google
scholar
.
de
esta
parte
tan
pequeñita
en
realidad
más
del
ochenta
por
ciento
lo
hemos
hecho
esa
pequeña
aldea
del
del
ICLEF
.
en
conclusión
está
claro
que
no
ha
recibido
la
atención
que
merece
.
así
que
vamos
a
decidársela
nosotros
.
vamos
a
ver
.
aquí
.
qué
hemos
hecho
en
el
ICLEF
.
en
realidad
el
ICLEF
llevamos
desde
el
dos
mil
uno
o
el
dos
mil
dos
haciendo
experimentos
.
y
siempre
los
hemos
hecho
con
esta
metodología
que
tenéis
en
esta
transparencia
.
que
es
una
metodología
guiada
por
hipótesis
.
uno
formula
una
hipótesis
sobre
el
proceso
de
búsqueda
.
normalmente
sobre
cómo
se
puede
ayudar
mejor
al
usuario
a
buscar
.
a
continuación
prepara
su
sistema
de
referencia
y
su
sistema
de
contraste
para
comprobar
esa
hipótesis
.
después
diseña
un
conjunto
de
consultas
que
son
las
tareas
que
van
a
tener
que
resolver
los
usuarios
.
y
después
tienes
este
problema
que
he
comentado
de
que
cuando
utilizas
un
sistema
para
resolver
un
problema
dado
ya
no
puedes
hacer
el
mismo
problema
con
otro
sistema
porque
ya
sabes
cómo
resolverlo
de
antemano
ya
tienes
experiencia
y
tienes
ahí
un
proceso
de
aprendizaje
.
así
que
lo
que
se
hace
es
utilizar
un
cuadrado
latino
que
es
básicamente
combinar
usuarios
consultas
y
sistemas
de
manera
que
no
se
produzcan
esos
problemas
.
por
ejemplo
también
que
resulte
que
claro
como
no
puedes
darle
al
mismo
usuario
la
misma
consulta
con
dos
sistemas
puedes
tener
a
unos
usuarios
utilizando
este
sistema
y
a
otros
usuarios
distintos
utilizando
el
otro
sistema
.
y
si
tienes
mala
suerte
y
los
primeros
son
más
torpes
tú
vas
a
concluir
que
el
sistema
A
es
peor
cuando
en
realidad
simplemente
son
más
torpes
.
o
puede
darse
el
caso
de
que
las
consultas
que
haces
con
un
sistema
sean
más
sencillas
que
las
otras
etcétera
.
entonces
para
eliminar
todos
esos
efectos
se
utiliza
ese
diseño
de
cuadrado
latino
en
el
que
se
van
rotando
preguntas
sistemas
y
consultas
.
así
que
las
características
de
esta
metodología
son
primero
que
es
completamente
controlada
.
tú
sientas
a
los
usuarios
y
les
dices
lo
que
tienen
que
hacer
.
no
es
nada
ecológica
.
tú
no
vas
a
sentarte
al
lado
de
una
persona
con
una
necesidad
sino
que
probablemente
llamas
a
tu
primo
le
coges
y
le
dices
ahora
imagínate
que
eres
un
perodista
y
que
necesitas
información
sobre
esto
.
hala
ponte
a
buscar
.
es
guiado
por
hipótesis
.
y
es
deductivo
claro
.
o
sea
tú
haces
la
hipótesis
y
vas
hacia
abajo
en
lugar
de
observar
cómo
la
gente
busca
y
a
partir
de
ahí
hacer
abstracción
.
lo
mejor
de
esta
metodología
es
que
es
consistente
desde
un
punto
de
vista
científico
.
y
lo
peor
es
que
tiene
un
una
relación
coste
beneficio
desastrosa
.
reclutar
entrenar
a
los
usuarios
alimentarlos
mientras
trabajan
pagarlos
es
es
un
coste
tremento
y
al
final
sólo
puedes
medir
un
aspecto
de
la
búsqueda
a
la
vez
.
tú
tienes
que
tener
dos
interfaces
idénticas
excepto
en
justo
aquello
que
te
permite
probar
tu
hipótesis
.
para
qué
hablaros
de
un
sistema
completo
con
un
conjunto
de
funcionalidades
.
eso
es
prácticamente
inviable
.
y
encima
como
el
coste
de
reclutar
y
entrenar
es
tan
alto
al
final
tienes
un
conjunto
reducido
de
usuarios
.
si
tienes
treinta
y
dos
usuarios
eso
ya
es
la
obra
del
Escorial
.
con
lo
cual
es
muy
difícil
extraer
conclusiones
que
sean
significativas
estadísticamente
.
así
que
desde
el
dos
mil
seis
nos
planteamos
primero
encontrar
escenarios
más
realistas
estamos
trabajando
con
con
un
corpus
de
noticias
que
están
en
muchos
idiomas
y
que
son
corpus
corparables
o
sea
el
contenido
es
aproximado
son
noticias
de
la
misma
fecha
.
entonces
claro
para
qué
quiere
uno
buscar
información
en
chino
que
ya
tiene
en
castellano
no
.
el
escenario
no
era
realmente
el
ideal
.
por
supuesto
queríamos
facilitar
la
participación
de
los
grupos
de
investigación
porque
con
este
coste
tan
alto
es
una
razón
buenísima
para
no
entrar
a
investigar
en
el
tema
.
y
también
queríamos
explorar
nuevos
diseños
experimentales
por
la
misma
razón
.
así
que
nos
fuimos
a
Flickr
.
ya
lo
os
lo
he
enseñado
antes
pero
una
de
las
cosas
más
interesantes
de
Flickr
para
nosotros
es
que
el
contenido
esencial
son
imágenes
que
es
independiente
del
idioma
pero
es
una
red
social
a
escala
mundial
donde
hay
comunidades
de
muchísimos
idiomas
distintos
.
y
la
prueba
de
que
el
idioma
no
es
una
pieza
clave
para
intercambiar
información
es
que
es
absolutamente
normal
encontrarse
imágenes
anotadas
con
información
distinta
en
muchos
idiomas
.
en
este
ejemplo
pues
tenemos
anotaciones
en
inglés
en
japonés
en
italiano
y
en
español
hechas
por
el
que
puso
la
imagen
y
por
la
gente
que
comenta
cosas
.
así
que
el
entorno
es
estupendo
para
estudiar
este
tipo
de
fenómenos
.
y
quisimos
cambiar
un
poco
la
la
metodología
típica
de
hacer
consultas
tipo
encuéntrame
fotografías
de
parlamentos
europeos
que
es
el
tipo
de
preguntas
que
siempre
se
hacen
en
el
CLEF
por
un
par
de
cosas
un
poquito
más
arriesgadas
.
una
tarea
creativa
que
es
precisamente
la
que
os
he
comentado
antes
.
encontrar
cinco
ilustraciones
para
un
artículo
sobre
el
cultivo
del
azafrán
en
Italia
.
el
usuario
se
leía
el
artículo
y
luego
buscaba
la
información
en
Flickr
.
y
luego
una
visual
que
da
título
a
la
charla
.
cómo
se
llama
la
playa
de
la
derecha
.
es
la
pregunta
que
al
final
se
reducía
a
encontrar
este
cangrejo
.
una
vez
que
encontrabas
el
cangrejo
era
cuando
ya
obtenías
acceso
a
la
información
sobre
el
nombre
de
la
playa
.
y
no
pusimos
ninguna
restricción
metodológica
.
no
sé
cómo
no
nos
echaron
del
CLEF
porque
en
el
CLEF
tú
das
una
metodología
y
la
gente
la
sigue
.
entonces
nosotros
dijimos
no
hay
metodología
.
nos
tendrían
que
haber
echado
.
pero
la
idea
es
no
sabemos
cuál
es
la
metodología
buena
.
la
que
hemos
usado
hasta
ahora
es
costosísima
y
no
nos
está
dando
realmente
resultados
.
y
por
lo
tanto
exploramos
cosas
muy
distintas
a
las
que
habíamos
hecho
hasta
ahora
como
por
ejmeplo
el
comportamiento
de
los
usuarios
frente
a
problemas
multilingües
que
hasta
entonces
no
era
algo
que
nosotros
directamente
hubieramos
trabajado
o
la
percepción
subjetiva
frente
a
las
tareas
.
una
tarea
como
la
de
ilustrar
un
un
documento
obviamente
la
percepción
la
satisfacción
del
usuario
es
un
parámetro
que
que
tiene
relevancia
.
sólo
voy
a
poner
un
ejemplo
del
tipo
de
resultados
que
tuvimos
.
muy
curioso
.
esto
es
una
gráfica
en
la
que
aquí
está
el
tiempo
de
búsqueda
.
el
usuario
empieza
a
buscar
aquí
y
se
le
acaba
el
tiempo
aquí
en
el
minuto
veinte
.
objetivo
entontrar
el
cangrejo
o
el
nombre
de
la
playa
.
y
estas
barras
son
el
uso
de
las
facilidades
de
traducción
.
la
interfaz
de
este
experimento
te
permitía
buscar
en
muchos
idiomas
al
mismo
tiempo
.
tú
podías
consultar
en
en
castellano
y
él
te
buscaba
en
tantos
idiomas
como
quisieras
dentro
de
no
sé
si
eran
cinco
o
seis
idiomas
posibles
.
cada
usuario
sabíamos
qué
idiomas
para
él
eran
nativos
qué
idiomas
eran
pasivos
es
decir
algo
como
por
ejemplo
el
francés
para
todos
los
castellanos
.
aunque
no
sepamos
hablarlo
en
general
reconocemos
de
qué
se
nos
está
hablando
no
.
eso
es
un
poco
tener
capacidad
pasiva
pero
no
activa
.
no
puedes
hacer
consultas
pero
puedes
entender
lo
que
te
devuelve
el
sistema
.
o
completamente
desconocido
tipo
para
mí
pues
el
chino
o
el
holandés
.
bien
y
esto
es
la
proporción
en
la
que
pedían
al
sistema
los
usuarios
que
les
incluyera
esos
idiomas
en
la
búsqueda
.
si
os
fijáis
los
idiomas
desconocidos
por
alguna
razón
están
aquí
abajo
.
el
usuario
no
sabía
en
qué
idioma
estaba
anotada
el
la
imagen
del
cangrejo
.
no
tenía
ni
idea
.
pero
tendía
a
no
seleccionar
los
idiomas
que
no
conocía
.
y
es
curioso
porque
ahí
aprendes
sobre
el
tipo
de
resistencias
que
tiene
el
personal
a
la
hora
de
hacer
búsqueda
multilingüe
.
llegaba
un
momento
aquí
por
el
minuto
entre
el
minuto
trece
y
quince
estaban
completamente
desesperados
.
la
frase
normalmente
era
dónde
está
el
maldito
cangrejo
con
variaciones
.
y
a
partir
de
ahí
empezaban
ya
desesperadamente
a
tocar
todos
los
botones
de
la
interfaz
y
añadían
el
holandés
y
efectivamente
la
imagen
estaba
en
holandés
.
algunos
hasta
la
encontraban
no
.
como
veis
aquí
al
final
ya
estaba
todo
todo
marcado
.
entonces
claro
eso
hay
que
tenerlo
en
cuenta
al
diseñar
un
sistema
.
no
puedes
diseñar
un
sistema
pensando
que
la
gente
está
encantada
de
buscar
en
chino
.
en
realidad
es
bastante
lógico
.
claro
.
pero
como
somos
informáticos
pues
no
lo
habíamos
previsto
.
bien
en
el
ICLEF
dos
mil
ocho
hemos
seguido
con
con
con
esta
tarea
de
búsqueda
en
Flickr
.
pero
la
hemos
cambiado
y
la
hemos
cambiado
sustancialmente
.
porque
aún
seguíamos
teniendo
un
entorno
de
laboratorio
en
el
que
reclutábamos
usuarios
los
sentábamos
y
al
final
teníamos
muy
poquitos
usuarios
muy
poquitas
consultas
con
lo
cual
era
muy
difícil
de
nuevo
extraer
conclusiones
sustanciales
.
así
que
lo
que
hemos
pensado
es
que
íbamos
a
hacer
una
tarea
simplemente
de
análisis
de
logs
.
y
nos
íbamos
a
concentrar
en
conseguir
muchísimos
usuarios
utilizando
un
sistema
multilingüe
.
y
luego
los
logs
de
la
interacción
con
el
sistema
eran
lo
que
íbamos
a
ofrecer
a
los
partipantes
en
la
tarea
para
estudiarlos
y
averiguar
cosas
sobre
cómo
los
usuarios
realizan
búsquedas
multilingües
.
un
poco
la
clave
que
nos
dio
el
éxito
fue
convertirlo
en
un
juego
.
cómo
podemos
conseguir
que
un
montón
de
gente
por
ahí
por
el
mundo
con
distintos
perfiles
de
idiomas
se
enganche
a
hacer
una
cosa
como
esta
.
pues
dándoles
dinero
.
no
.
no
os
creáis
.
no
es
suficiente
.
sobre
todo
si
se
los
das
de
antemano
.
es
mejor
hacer
un
juego
.
si
lo
haces
a
escala
global
por
razones
que
todavía
no
alcanzo
a
comprender
la
gente
se
engancha
con
la
idea
de
que
hay
un
ranking
y
que
puedes
estar
mejor
o
peor
.
vamos
a
probar
a
ver
si
así
lo
conseguimos
no
.
y
el
juego
tenía
que
ser
extremadamente
simple
claro
porque
no
podíamos
entrenar
a
los
usuarios
ni
explicarles
ni
cómo
funcionaba
la
interfaz
ni
de
qué
iba
el
juego
.
así
que
el
más
simple
posible
es
ves
esta
imagen
.
encuéntrala
.
que
por
cierto
a
priori
parece
una
tarea
un
poco
absurda
no
.
si
ya
tengo
la
imagen
para
qué
voy
a
encontrarla
.
pero
en
realidad
yo
creo
que
es
algo
que
hacemos
todos
continuamente
.
ese
artículo
que
había
visto
no
sé
dónde
de
cómo
se
llamaba
.
y
estás
buscando
ese
artículo
y
estás
buscando
esa
foto
tan
bonita
que
vi
el
otro
día
de
o
que
tengo
en
mi
propia
colección
.
o
sea
que
en
realidad
es
una
tarea
bastante
bastante
práctica
.
y
entonces
lo
que
hicimos
fue
una
interfaz
que
te
da
una
asistencia
estándar
para
hacer
búsqueda
traslingüe
para
buscar
en
varios
idiomas
simultáneamente
.
y
esa
interfaz
conectarla
con
la
API
de
de
Flickr
.
y
lo
más
importante
de
todo
eso
sí
necesitábamos
que
los
usuarios
se
registraran
porque
necesitábamos
saber
cuál
es
cuál
era
su
idioma
nativo
y
cuáles
eran
su
perfil
de
conocimiento
del
resto
de
los
idiomas
los
seis
que
contemplamos
.
cuánto
me
queda
.
bueno
pues
os
voy
a
enseñar
un
poquito
la
interfaz
para
que
veáis
de
qué
iba
.
esta
es
la
imagen
.
si
pinchabas
la
veías
más
grande
.
y
tenías
que
encontrarla
no
.
pues
aquí
en
este
caso
por
ejemplo
violín
Strauss
estátua
.
este
era
un
un
tío
informado
además
un
tío
listo
.
eh
la
búsqueda
simultánea
en
seis
idiomas
tú
el
usuario
podía
seleccionar
o
deseleccionar
cualquiera
de
ellos
.
y
entonces
el
sistema
te
enseña
las
traducciones
que
está
eligiendo
en
cada
momento
para
cada
uno
de
los
términos
de
la
consulta
.
lo
hacíamos
de
dos
maneras
.
hay
una
información
contextual
que
es
Flickr
que
tiene
toda
la
información
de
concurrencia
de
las
tags
en
la
base
de
datos
tú
le
puedes
decir
que
te
dé
etiquetas
relacionadas
con
violín
strauss
y
estatua
con
las
tres
a
la
vez
.
y
como
la
base
de
datos
es
tan
multilingüe
y
hay
tanta
anotación
cruzada
entre
idomas
hay
cierta
posibilidad
de
que
la
traducción
para
estas
palabras
en
cualquiera
de
estos
idiomas
aparezca
en
las
sugerencias
de
Flickr
.
así
que
esa
era
un
poco
la
evidencia
que
usábamos
contextual
de
la
consulta
.
y
luego
además
utilizábamos
otras
técnicas
de
simplemente
parecido
de
de
similitud
entre
cadenas
no
.
bueno
sí
.
la
si
esta
traducción
se
parece
más
al
origen
es
quizás
más
probable
que
otras
que
no
se
parecen
nada
.
así
que
bueno
un
sistema
digamos
también
de
referencia
no
especialmente
malo
pero
tampoco
estado
del
arte
respecto
a
la
calidad
de
las
traducciones
.
esas
traducciones
se
convertían
en
una
búsqueda
booleana
.
aquí
tien
o
sea
había
en
la
en
las
imágenes
tiene
que
haber
al
menos
una
de
las
traducciones
posibles
para
violín
y
al
menos
una
de
las
traducciones
posibles
para
Strauss
y
al
menos
una
de
las
traducciones
posibles
para
.
no
me
acuerdo
cuál
era
la
otra
.
estatua
claro
.
gracias
.
además
implementamos
también
un
mecanismo
básico
de
relevance
feedback
de
realimentación
que
es
para
cualquiera
de
las
palabras
que
sugiere
Flickr
o
sea
aquí
tienes
las
sugerencias
de
Flickr
la
la
el
mecanismo
de
realimentación
de
Flickr
estándar
.
y
luego
además
tenemos
los
términos
de
las
imágenes
que
van
apareciendo
.
cualquier
momento
al
pinchar
sobre
ellos
el
usuario
podía
o
lanzar
una
nueva
consulta
con
ese
término
o
añadir
el
término
a
la
consulta
y
volverla
a
lanzar
.
y
además
le
dábamos
información
de
traducción
si
la
teníamos
.
en
este
caso
al
pinchar
en
park
pues
se
le
dice
que
en
inglés
significa
parque
en
alemán
parque
y
en
holandés
también
significa
parque
.
una
cosa
fundamental
era
la
traducción
asistida
de
la
consulta
.
la
idea
aquí
de
nuevo
es
que
el
humano
y
la
máquina
juntos
pueden
conseguir
una
traducción
óptima
para
la
consulta
.
entonces
si
en
un
momento
dado
no
te
gustaba
una
traducción
para
un
término
al
pinchar
veías
todos
los
posibles
del
diciconario
.
y
puedes
o
bien
seleccionar
alguno
alternativo
o
añadirlo
simplemente
o
bien
escribir
una
traducción
nueva
si
te
parecía
que
la
traducción
correcta
no
estaba
en
el
diccionario
.
había
perfiles
de
usuario
lo
más
importante
como
he
comentado
antes
pues
este
usuario
saber
que
su
lengua
nativa
es
el
español
que
no
conoce
en
absoluto
el
alemán
y
holandés
y
que
el
francés
y
el
italiano
puede
comprender
lo
que
ve
y
un
ranking
esta
es
como
os
digo
la
parte
fundamental
para
enganchar
a
los
usuarios
.
este
era
el
ranking
el
que
cada
uno
podía
ver
su
posición
global
respecto
al
resto
del
mundo
en
términos
de
la
puntuación
que
les
estábamos
dando
por
encontrar
las
imágenes
.
y
además
también
había
un
ranking
de
grupos
que
funcionaba
bastante
.
el
pique
entre
grupos
es
bastante
efectivo
.
en
nuestra
escuela
funcionó
entre
departamentos
razonablemente
.
por
cierto
nos
ganaron
no
nuestro
departamento
no
fue
el
el
mejor
.
y
por
último
pero
esto
fue
muy
importante
es
un
mecanismo
de
pistas
.
por
qué
.
porque
la
la
tarea
es
increíblemente
difícil
.
estamos
hablando
de
doscientos
millones
de
imágenes
seis
idiomas
al
mismo
tiempo
.
cuando
empezamos
a
hacer
pruebas
la
gente
nos
decía
os
habéis
vuelto
locos
.
esto
es
imposible
.
aquí
no
hay
forma
de
encontrar
nada
.
así
que
para
que
los
usuarios
no
se
nos
desesperaran
implementamos
un
sistema
de
pistas
.
si
te
rindes
el
sistema
te
ofrece
una
pista
.
la
primera
siempre
es
el
idioma
.
con
lo
cual
pasamos
de
un
modo
multilingüe
a
un
modo
bilingüe
lo
cual
nos
venía
muy
bien
luego
para
comparar
y
para
estudiar
.
y
las
siguientes
pistas
son
palabras
clave
de
la
imagen
.
en
un
momento
dado
con
tres
o
cuatro
cuatro
o
cinco
pistas
era
sencillísimo
.
ahora
eso
sí
cada
vez
que
el
usuario
pide
una
pista
le
quitamos
puntos
.
con
esto
la
cosa
empezó
a
funcionar
.
y
este
es
el
resultado
.
esta
es
la
transparencia
más
importante
de
mi
charla
.
y
es
eh
que
por
primera
vez
que
yo
sepa
hemos
conseguido
un
un
dataset
una
test
suite
o
como
queráis
llamarlo
reutilizable
en
en
unos
experimentos
interactivos
.
normalmente
coges
los
usuarios
los
utilizas
miras
los
resultados
y
se
acabó
.
ya
no
se
puede
hacer
nada
más
.
aquí
hemos
llegado
a
algo
que
es
parecido
a
lo
que
se
hace
en
otras
tareas
.
es
coger
un
conjunto
de
datos
que
sin
más
interacciones
con
el
usuario
la
gente
puede
utilizar
para
estudiar
los
logs
y
para
sacar
conclusiones
.
conseguimos
finalmente
tener
trescientos
doce
usuarios
repartidos
en
cuarenta
y
un
grupos
distintos
de
cuarenta
y
tres
países
.
ahí
tenéis
un
mapita
más
o
menos
de
el
el
despliegue
por
países
.
y
la
verdad
es
que
es
fantástico
.
tenemos
de
casi
todos
los
continentes
.
utilizamos
un
conjunto
que
preparamos
de
ciento
ocho
consultas
que
también
es
muchísimo
mayor
de
lo
que
se
había
hecho
antes
.
la
colección
como
os
digo
tiene
del
orden
de
doscientos
millones
de
imágenes
por
lo
menos
.
o
sea
que
también
es
algo
serio
.
por
desgracia
no
los
tenemos
.
tenemos
que
trabajar
con
la
API
que
es
una
limitación
muy
grande
.
y
finalmente
conseguimos
recolectar
cinco
mil
ciento
una
sesiones
completas
de
búsquedas
que
es
un
material
que
ya
te
sirve
para
hacer
un
poquito
de
análisis
estadístico
y
ver
diferencias
.
además
cada
sesión
una
vez
que
el
usuario
o
bien
se
rendía
o
bien
encontraba
la
imagen
rellenaba
un
cuestionario
.
así
que
tenemos
cinco
mil
ciento
un
cuestionarios
post
búsqueda
.
esto
es
maravilloso
.
casi
nos
desmayamos
cuando
vemos
estas
cifras
.
y
además
hubo
setenta
y
tres
usuarios
que
completaron
quince
búsquedas
.
estos
se
tiraron
una
semana
jugando
con
el
sistema
.
y
al
acabar
las
quince
búsquedas
el
sistema
automáticamente
saltaba
con
un
formulario
post
experiencia
no
.
entonces
ya
a
los
usuarios
experimentados
tenemos
setenta
y
tres
cuestionarios
sobre
cómo
fue
la
experiencia
.
y
multitud
de
perfiles
.
había
muchos
investigadores
en
recuperación
de
información
pero
también
había
muchísimos
fans
de
fotografía
que
se
picaban
en
los
blogs
de
fotografía
.
muchos
estudiantes
de
lingüística
a
los
que
al
parecer
les
habían
prometido
una
subida
de
nota
si
ganaban
y
cosas
de
esas
.
en
fin
de
todo
.
grupos
monitorizados
también
.
hubo
experimentos
en
los
que
siguieron
con
el
mecanismo
tradicional
reclutar
usuarios
lo
cual
está
muy
bien
porque
puedes
observarles
.
estudio
observacional
es
muy
importante
.
y
bien
esto
es
un
poco
.
gran
variedad
de
idiomas
nativos
de
idiomas
de
la
interfaz
gran
variedad
entre
cada
uno
de
los
idiomas
de
la
interfaz
entre
los
perfiles
.
aquí
véis
que
por
ejemplo
para
el
inglés
la
mayoría
eran
activos
que
es
el
rojo
sin
embargo
para
el
holandés
la
inmensa
mayoría
era
completamente
desconocido
.
en
fin
un
poco
el
mensaje
es
enorme
variedad
.
y
os
voy
a
enseñar
un
par
de
resultados
nada
más
.
el
primero
es
la
tasa
de
éxito
por
perfiles
una
cosa
que
estudiamos
en
la
UNED
.
dependiendo
de
si
la
imagen
estaba
en
un
en
un
idioma
que
para
el
usuario
era
un
idioma
activo
o
era
un
idioma
pasivo
o
no
lo
conocía
en
absoluto
queríamos
ver
si
la
tasa
de
de
éxito
cambiaba
o
no
.
si
os
fijáis
aquí
curiosamente
entre
activo
y
pasivo
casi
no
hay
diferencia
.
que
eso
es
un
resultado
que
nos
sorprendió
bastante
.
sin
embargo
entre
activo
y
desconocido
pues
hay
como
un
veinte
por
ciento
de
o
sea
los
activos
encuentran
un
veinte
por
ciento
más
de
información
.
es
una
diferencia
sustancial
.
es
grande
.
no
es
grande
.
aquí
todo
es
muy
muy
engañoso
porque
podemos
concluir
que
éstas
son
la
diferencia
de
dificualtad
entre
las
las
tareas
.
es
una
pregunta
a
ver
alguien
me
sabe
contestar
.
Isidro
tú
qué
dirías
.
bueno
esto
es
muy
rápido
porque
la
respuesta
es
que
no
porque
hay
un
mecanismo
de
pistas
.
si
el
.
yo
encuentro
la
imagen
pidiendo
pistas
.
entonces
en
un
momento
dado
estas
diferencias
no
significan
nada
si
no
vemos
cuántas
pistas
está
pidiendo
cada
uno
de
los
perfiles
.
bueno
pues
afortunadamente
aquí
sí
es
lo
que
nos
esperábamos
.
no
solamente
encuentran
más
imágenes
sino
que
es
que
piden
muchas
menos
pistas
o
sea
que
están
resolviendo
una
tarea
más
difícil
con
con
bastante
más
acierto
.
fijaos
que
esto
no
significa
que
tarden
más
los
usuarios
desconocidos
que
a
veces
se
puede
establecer
la
dificultad
de
una
tarea
en
términos
del
tiempo
que
tardas
en
completarla
.
no
no
.
es
que
se
rinden
.
independientemente
de
que
tardebn
más
o
menos
se
rinden
.
y
dicen
I
give
up
.
me
rindo
.
no
puedo
más
.
entonces
están
pidiendo
bastantes
más
pistas
.
dos
con
cuarenta
y
dos
es
mucho
porque
la
primera
es
el
idioma
de
destino
.
están
pidiendo
además
una
keyword
y
media
.
con
tres
keywords
ya
empieza
a
ser
muy
facilito
.
o
sea
que
están
pidiendo
mucha
más
información
pero
no
son
capaces
de
alcanzar
esos
niveles
de
eficacia
ni
de
lejos
.
y
además
si
miramos
al
coste
cognitivo
.
cuando
digo
coste
cognitivo
me
refiero
al
número
de
interacciones
con
el
sistema
porque
el
tiempo
es
.
teníamos
la
información
del
tiempo
pero
no
era
relevante
no
porque
a
lo
mejor
teníamos
un
usuario
que
se
iba
a
a
tomar
un
café
y
luego
volvía
y
seguía
.
o
incluso
que
abandonaba
se
le
dejaba
quedaba
abierta
la
ventana
y
volvía
al
día
siguiente
.
eso
está
fuera
de
control
.
así
que
en
términos
del
número
de
interacciones
por
ejemplo
el
número
de
consultas
el
número
de
veces
que
se
explora
el
ranking
y
se
piden
veinte
más
el
número
de
veces
que
se
utilizan
los
mecanismos
de
refinamiento
pues
vemos
que
en
general
la
tendencia
de
nuevo
es
la
misma
.
o
sea
que
los
que
están
buscando
en
un
idioma
desconocido
hacen
muchas
más
interacciones
.
o
sea
tienen
un
coste
cognitivo
mayor
a
pesar
de
que
es
un
problema
más
sencillo
porque
piden
más
pistas
.
y
aún
así
son
mucho
menos
eficaces
a
la
hora
de
encontrar
imágenes
.
otro
aspecto
interesante
es
el
aprendizaje
.
también
pensábamos
igual
por
ejemplo
al
al
final
al
cabo
de
quince
consultas
igual
han
aprendido
que
las
los
mecanismos
de
ayuda
a
la
a
la
interacción
a
refinar
las
consultas
que
merece
la
pena
.
estábamos
muy
interesados
en
ver
si
eran
capaces
de
aprender
a
utilizar
esos
mecanismos
para
buscar
mejor
.
y
esta
fue
una
sorpresa
que
de
nuevo
no
tenía
que
haberla
sido
que
es
la
siguiente
.
aquí
vemos
la
primera
desde
la
primera
consulta
hasta
la
consulta
número
quince
la
azul
es
el
número
de
pistas
promedio
que
se
piden
y
la
roja
es
el
el
la
tasa
de
éxito
al
encontrar
imágenes
.
éstas
son
estadísticas
sobre
un
montón
de
o
sea
son
sobre
sobre
miles
de
de
experiencias
.
pues
curiosamente
la
tasa
de
éxito
es
constante
.
no
mejora
.
lo
que
sube
es
la
la
el
número
de
pistas
que
piden
.
al
final
la
conclusión
es
que
el
usuario
siempre
como
la
bola
cuando
rueda
por
la
montaña
siempre
escoge
el
camino
de
menos
coste
de
bajada
de
potencia
no
.
y
entonces
se
dieron
cuenta
de
que
merecía
la
pena
pedir
alguna
pista
aunque
te
te
quitaran
puntos
porque
hacías
la
tarea
muchísimo
más
fácil
.
así
que
curiosamente
lo
que
nuestros
usuarios
aprendieron
fue
a
pedir
alguna
pista
más
.
y
todo
lo
demás
baja
.
esto
es
el
coste
cognitivo
el
azul
es
el
número
de
consultas
que
se
hacen
.
el
rojo
es
el
uso
de
las
facilidades
de
refinamiento
y
el
el
verde
el
número
de
veces
que
se
explora
el
ranking
.
veis
que
es
una
bajada
.
o
sea
aprender
la
tarea
no
ha
significado
en
este
caso
utilizar
más
las
facilidades
de
la
interfaz
sino
que
lo
que
ha
significado
es
hacerla
más
rápido
aprender
cuál
es
el
camino
óptimo
para
hacerla
más
rápido
con
menos
esfuerzo
.
aquí
hay
un
dato
interesante
.
estos
son
los
cuestionarios
que
se
les
hacían
a
los
usuarios
cuando
encontraban
una
imagen
.
de
esto
tenemos
también
por
tanto
miles
de
ellos
.
y
estas
son
las
preguntas
.
se
le
decía
bueno
una
pregunta
era
cuál
fue
la
mayor
dificultad
para
encontrar
imágenes
.
entonces
resulta
que
cuando
la
imagen
era
activa
.
perdón
sí
cuando
la
imagen
estaba
anotada
en
un
idioma
activo
a
ver
si
consigo
aquí
pues
vemos
el
rojo
son
los
que
los
que
contestan
cuando
el
idioma
era
activo
.
y
el
.
y
el
ratón
ya
me
está
fallando
.
la
pregunta
.
bueno
aparte
de
esta
que
es
fue
fácil
que
encontrado
.
y
lógicamente
a
muchos
ya
sabéis
esto
los
matemáticos
cuando
resuelven
un
problema
aunque
lleven
diez
años
dicen
era
es
trivial
pues
esto
es
parecido
no
.
lo
han
encontrado
pues
es
fácil
.
pero
bueno
si
descartamos
esta
primera
columna
de
esta
primera
pregunta
vemos
que
la
causa
más
importante
es
la
cuatro
era
difícil
describir
la
imagen
.
y
la
siguiente
es
la
dos
había
demasiadas
imágenes
.
esto
es
cuando
el
idioma
era
activo
.
ahora
cuando
el
idioma
era
desconocido
y
este
es
el
amarillo
la
causa
principal
es
que
no
sabían
que
no
conocía
el
idioma
en
que
estaba
anotada
la
imagen
.
y
la
siguiente
es
era
difícil
porque
tenía
que
traducir
mi
consulta
.
a
dónde
quiero
llegar
a
que
cuando
hay
un
problema
traslingüe
cuando
no
conocemos
el
idioma
ese
es
el
factor
de
dificultad
más
importante
.
ese
es
en
el
que
se
tiene
que
concentrar
el
sistema
o
la
interfaz
.
porque
la
percepción
es
esa
.
eso
pasa
a
ser
el
factor
de
dificultad
.
y
fijaos
que
la
tarea
era
muy
difícil
.
o
sea
que
que
que
efectivamente
la
base
de
datos
es
gigantesca
.
y
es
complicado
encontrar
una
imagen
en
concreto
en
ella
.
hay
que
acabar
no
vale
.
pues
solamente
voy
a
enseñaros
.
bueno
no
merece
la
pena
.
solamente
os
voy
a
decir
una
cosa
.
las
facilidades
la
asistencia
translingüe
para
traducir
la
consulta
para
seleccionar
mejor
las
las
traducciones
etcétera
se
usaban
muy
poco
.
es
verdad
que
es
la
única
.
veis
es
esta
gráfica
.
es
la
única
que
no
baja
.
todo
lo
demás
baja
.
esta
no
.
nosotros
queríamos
ver
si
efectivamente
la
gente
aprendía
a
usarlo
y
se
emocionaba
con
lo
de
tocar
la
la
traducción
para
mejorarlo
.
no
lo
vimos
.
pero
al
menos
es
la
que
de
hecho
según
como
quieras
interpretar
todos
estos
saltos
se
puede
ver
que
sube
un
poco
.
pero
el
uso
en
general
es
muy
bajo
.
esto
estamos
hablando
de
usarlo
en
tres
de
cada
diez
.
no
tres
de
cada
.
sí
tres
de
cada
diez
consultas
hacen
algo
con
esa
facilidad
.
o
sea
que
el
uso
en
terminos
absolutos
es
es
muy
bajo
.
sin
embargo
la
los
usuarios
aquí
contestaban
si
eso
les
había
parecido
útil
o
no
al
final
de
las
quince
búsquedas
.
entonces
decían
la
posibilidad
de
de
mejorar
las
traducciones
a
través
del
del
mecanismo
de
refinamiento
del
sistema
me
parecía
muy
útil
estaba
muy
de
acuerdo
en
que
es
muy
útil
es
el
azul
útil
y
nos
vamos
hasta
aquí
y
estos
son
los
que
le
parecía
poco
útil
o
nada
útil
.
fijaos
que
tenemos
más
del
setenta
por
ciento
que
les
parecía
muy
útil
o
útil
.
y
esto
es
de
lo
de
las
cifras
más
altas
en
lo
que
están
contestando
.
o
sea
lo
usan
poco
pero
les
parece
utilísimo
.
es
curioso
no
.
esto
es
el
efecto
el
efecto
humanos
.
o
no
porque
en
realidad
tiene
sentido
.
cuántos
de
vosotros
usáis
el
modo
avanzado
de
búsqueda
en
Google
.
no
sé
.
yo
lo
he
usado
pocas
veces
.
ahora
cuando
lo
uso
si
no
lo
tuviera
estaría
.
o
sea
si
me
preguntan
por
el
modo
avanzado
de
Google
voy
a
decir
fenomenal
.
por
ejemplo
la
detección
de
caras
cuando
buscas
imágenes
en
Google
tú
puedes
decirle
quédate
sólo
con
las
caras
.
normalmente
no
lo
usas
.
ahora
cuando
lo
usas
te
parece
fabuloso
.
y
si
probablemente
en
un
cuestionario
dirías
esto
es
estupendo
.
esto
es
un
poco
parecido
.
hay
que
aprender
a
ocultarle
al
usuario
los
problemas
derivados
de
buscar
en
varios
idiomas
.
porque
eso
a
él
no
le
interesa
.
a
él
le
interesa
encontrar
información
encontrar
imágenes
en
este
caso
.
no
le
interesa
si
están
en
un
idioma
u
otro
.
él
no
quiere
hacer
una
búsqueda
multilingüe
.
quiere
encontrar
información
.
ahora
cuando
no
la
encuentra
entonces
tienes
que
tener
esos
mecanismos
para
que
realmente
se
pueda
finalmente
completar
la
tarea
.
bueno
pues
pues
ya
está
yo
creo
que
.
no
voy
a
repasar
las
conclusiones
porque
son
más
o
menos
lo
que
hemos
comentado
ya
.
así
que
si
tenéis
alguna
consulta
para
el
cangrejo
.
.
